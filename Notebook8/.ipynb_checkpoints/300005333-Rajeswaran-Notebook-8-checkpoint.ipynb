{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awT15gnsFWm7"
   },
   "source": [
    "# Notebook 8 - Knowledge Representation (KR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnqB_KDcFWnC"
   },
   "source": [
    "CSI4106 Artificial Intelligence  \\\n",
    "Fall 2021 \\\n",
    "Version 1 (2020) prepared by Julian Templeton and Caroline Barrière.  Version 2 (2021) revised by Caroline Barrière."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvXh97W1FWnE"
   },
   "source": [
    "***INTRODUCTION***:  \n",
    "\n",
    "When reading text, understanding the type of entities within the text helps to infer additional information about the entity. For example, if a text mentions *Canada*, knowing that it is a GPE (geopolitical entity), already indicates to us that this entity has a supercify, a population, etc. Through the use of Named Entity Recognition (NER), we are able to determine whether an entity is a Person, Organization, Country, ... \n",
    "\n",
    "When exploring text online, we also occassionally see entities have clickable links to webpages with more information on the entity. This is a form of enhancement of the text to allow readers to easily access the information needed to understand each entity from the text and its content.  If we take the example of Canada again, if we transform it into [Canada](https://en.wikipedia.org/wiki/Canada), using entity linking we access more information.\n",
    "\n",
    "In this notebook we will be revisiting the Covid-19 related news dataset from notebook 7 to explore how we can improve spaCy's NER and enhance the text from the news articles through the use of entity linking. This will be done in three parts: \n",
    "\n",
    "(1) we explore the results of spaCy's NER  \\\n",
    "(2) we use text coherence for post-processing spaCy's NER results \\\n",
    "(3) we perform text enhancement with entity linking.    \n",
    "\n",
    "This notebook uses libraries that have been used in previous notebooks, including spaCy and pandas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHAqTKhhFWnF"
   },
   "source": [
    "***HOMEWORK***:  \n",
    "Go through the notebook by running each cell, one at a time.  \n",
    "Look for **(TO DO)** for the tasks that you need to perform. Do not edit the code outside of the questions which you are asked to answer unless specifically asked. Once you're done, sign the notebook (at the end of the notebook), rename it to *StudentNum-LastName-Notebook8.ipynb* and submit it.  \n",
    "\n",
    "*The notebook will be marked on 30.  \n",
    "Each **(TO DO)** has a number of points associated with it.*\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-v9uH8KAFWnG"
   },
   "outputs": [],
   "source": [
    "# Before starting we will import every module that we will be using\n",
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "R1quNi_vFWnI"
   },
   "outputs": [],
   "source": [
    "# The core spacy object can be used for tokenization, lemmatization, POS Tagging, NER, ...\n",
    "# Note that this is specifically for the English language and requires the English package to be installed\n",
    "# via pip to work as intended.\n",
    "\n",
    "# sp = spacy.load('en')\n",
    "\n",
    "# If the above causes an error after installing the package \n",
    "# then install the package as below\n",
    "# !spacy download en_core_web_sm\n",
    "sp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-O-ToHsLaHa"
   },
   "source": [
    "Similarly to the last notebook, the dataset is provided on Brightspace (Module 8) along with this notebook, but details regarding Covid-19 news dataset can be found [here](https://www.kaggle.com/ryanxjhan/cbc-news-coronavirus-articles-march-26?select=news.csv). The first thing that we will do, as usual, is load the file into a pandas dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UCZjUSFOFWnL"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>'More vital now:' Gay-straight alliances go vi...</td>\n",
       "      <td>2020-05-03 1:30</td>\n",
       "      <td>Lily Overacker and Laurell Pallot start each g...</td>\n",
       "      <td>Lily Overacker and Laurell Pallot start each g...</td>\n",
       "      <td>https://www.cbc.ca/news/canada/calgary/gay-str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>Scientists aim to 'see' invisible transmission...</td>\n",
       "      <td>2020-05-02 8:00</td>\n",
       "      <td>Some researchers aim to learn more about how t...</td>\n",
       "      <td>This is an excerpt from Second Opinion, a week...</td>\n",
       "      <td>https://www.cbc.ca/news/technology/droplet-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['The Canadian Press']</td>\n",
       "      <td>Coronavirus: What's happening in Canada and ar...</td>\n",
       "      <td>2020-05-02 11:28</td>\n",
       "      <td>Canada's chief public health officer struck an...</td>\n",
       "      <td>The latest:  The lives behind the numbers: Wha...</td>\n",
       "      <td>https://www.cbc.ca/news/canada/coronavirus-cov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>B.C. announces 26 new coronavirus cases, new c...</td>\n",
       "      <td>2020-05-02 18:45</td>\n",
       "      <td>B.C. provincial health officer Dr. Bonnie Henr...</td>\n",
       "      <td>B.C. provincial health officer Dr. Bonnie Henr...</td>\n",
       "      <td>https://www.cbc.ca/news/canada/british-columbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>B.C. announces 26 new coronavirus cases, new c...</td>\n",
       "      <td>2020-05-02 18:45</td>\n",
       "      <td>B.C. provincial health officer Dr. Bonnie Henr...</td>\n",
       "      <td>B.C. provincial health officer Dr. Bonnie Henr...</td>\n",
       "      <td>https://www.cbc.ca/news/canada/british-columbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>['Senior Writer', 'Chris Arsenault Is A Senior...</td>\n",
       "      <td>Brazil has the most confirmed COVID-19 cases i...</td>\n",
       "      <td>2020-05-02 8:00</td>\n",
       "      <td>From describing coronavirus as a \"little flu,\"...</td>\n",
       "      <td>With infection rates spiralling, some big city...</td>\n",
       "      <td>https://www.cbc.ca/news/world/brazil-has-the-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>The latest on the coronavirus outbreak for May 1</td>\n",
       "      <td>2020-05-01 20:43</td>\n",
       "      <td>The latest on the coronavirus outbreak from CB...</td>\n",
       "      <td>Coronavirus Brief (CBC)  Canada is officiall...</td>\n",
       "      <td>https://www.cbc.ca/news/the-latest-on-the-coro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>Coronavirus: What's happening in Canada and ar...</td>\n",
       "      <td>2020-05-01 11:51</td>\n",
       "      <td>Nova Scotia announced Friday it is immediately...</td>\n",
       "      <td>The latest:  The lives behind the numbers: Wha...</td>\n",
       "      <td>https://www.cbc.ca/news/canada/coronavirus-cov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>['Senior Writer', \"Adam Miller Is Senior Digit...</td>\n",
       "      <td>Did the WHO mishandle the global coronavirus p...</td>\n",
       "      <td>2020-04-30 8:00</td>\n",
       "      <td>The World Health Organization has come under f...</td>\n",
       "      <td>The World Health Organization has come under f...</td>\n",
       "      <td>https://www.cbc.ca/news/health/coronavirus-who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>['Thomson Reuters']</td>\n",
       "      <td>Armed people in Michigan's legislature protest...</td>\n",
       "      <td>2020-04-30 21:37</td>\n",
       "      <td>Hundreds of protesters, some armed, gathered a...</td>\n",
       "      <td>Hundreds of protesters, some armed, gathered a...</td>\n",
       "      <td>https://www.cbc.ca/news/world/protesters-michi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                            authors  \\\n",
       "0          0                                                 []   \n",
       "1          1                                                 []   \n",
       "2          2                             ['The Canadian Press']   \n",
       "3          3                                                 []   \n",
       "4          4                                                 []   \n",
       "5          5  ['Senior Writer', 'Chris Arsenault Is A Senior...   \n",
       "6          6                                       ['Cbc News']   \n",
       "7          7                                       ['Cbc News']   \n",
       "8          8  ['Senior Writer', \"Adam Miller Is Senior Digit...   \n",
       "9          9                                ['Thomson Reuters']   \n",
       "\n",
       "                                               title      publish_date  \\\n",
       "0  'More vital now:' Gay-straight alliances go vi...   2020-05-03 1:30   \n",
       "1  Scientists aim to 'see' invisible transmission...   2020-05-02 8:00   \n",
       "2  Coronavirus: What's happening in Canada and ar...  2020-05-02 11:28   \n",
       "3  B.C. announces 26 new coronavirus cases, new c...  2020-05-02 18:45   \n",
       "4  B.C. announces 26 new coronavirus cases, new c...  2020-05-02 18:45   \n",
       "5  Brazil has the most confirmed COVID-19 cases i...   2020-05-02 8:00   \n",
       "6   The latest on the coronavirus outbreak for May 1  2020-05-01 20:43   \n",
       "7  Coronavirus: What's happening in Canada and ar...  2020-05-01 11:51   \n",
       "8  Did the WHO mishandle the global coronavirus p...   2020-04-30 8:00   \n",
       "9  Armed people in Michigan's legislature protest...  2020-04-30 21:37   \n",
       "\n",
       "                                         description  \\\n",
       "0  Lily Overacker and Laurell Pallot start each g...   \n",
       "1  Some researchers aim to learn more about how t...   \n",
       "2  Canada's chief public health officer struck an...   \n",
       "3  B.C. provincial health officer Dr. Bonnie Henr...   \n",
       "4  B.C. provincial health officer Dr. Bonnie Henr...   \n",
       "5  From describing coronavirus as a \"little flu,\"...   \n",
       "6  The latest on the coronavirus outbreak from CB...   \n",
       "7  Nova Scotia announced Friday it is immediately...   \n",
       "8  The World Health Organization has come under f...   \n",
       "9  Hundreds of protesters, some armed, gathered a...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Lily Overacker and Laurell Pallot start each g...   \n",
       "1  This is an excerpt from Second Opinion, a week...   \n",
       "2  The latest:  The lives behind the numbers: Wha...   \n",
       "3  B.C. provincial health officer Dr. Bonnie Henr...   \n",
       "4  B.C. provincial health officer Dr. Bonnie Henr...   \n",
       "5  With infection rates spiralling, some big city...   \n",
       "6    Coronavirus Brief (CBC)  Canada is officiall...   \n",
       "7  The latest:  The lives behind the numbers: Wha...   \n",
       "8  The World Health Organization has come under f...   \n",
       "9  Hundreds of protesters, some armed, gathered a...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.cbc.ca/news/canada/calgary/gay-str...  \n",
       "1  https://www.cbc.ca/news/technology/droplet-tra...  \n",
       "2  https://www.cbc.ca/news/canada/coronavirus-cov...  \n",
       "3  https://www.cbc.ca/news/canada/british-columbi...  \n",
       "4  https://www.cbc.ca/news/canada/british-columbi...  \n",
       "5  https://www.cbc.ca/news/world/brazil-has-the-m...  \n",
       "6  https://www.cbc.ca/news/the-latest-on-the-coro...  \n",
       "7  https://www.cbc.ca/news/canada/coronavirus-cov...  \n",
       "8  https://www.cbc.ca/news/health/coronavirus-who...  \n",
       "9  https://www.cbc.ca/news/world/protesters-michi...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset, show top ten rows\n",
    "df = pd.read_csv(\"news.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joFg7xQBFWnJ"
   },
   "source": [
    "**PART 1 - SpaCy's NER**  \n",
    "  \n",
    "Let's start by looking at the NER that is performed by spaCy.  SpaCy's documentation does not tell us how exactly their NER is done (certainly their trade secret), but we can at least look at the results.\n",
    "\n",
    "As we've talked about in previous notebooks, when evaluating a process or a tool, we can do quantitative or **qualitative evaluation** of results.  In this notebook, we work at a qualitative level, meaning that we are not measuring metrics such as precision/recall on a large amount of data, but rather printing results of a few examples and try to understand these results.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AFuQJavFWnO"
   },
   "source": [
    "Below is the same sentence example as in the last notebook, for which we had looked at POS-tagging and other linguistic processes.  We now use this sentence to show how to access spaCy's NER type predictions for tokens in a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QAhxdWmOFWnP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Canada\" is a GPE\n",
      "\"at least two metres\" is a CARDINAL\n",
      "\"COVID-19\" is a ORG\n"
     ]
    }
   ],
   "source": [
    "# Same example from notebook 7, recall that we loop through the iterator found in the .ents property of a parsed sentence\n",
    "sentence_example = \"Government guidelines in Canada recommend that people stay at least two metres away from others as part of physical distancing measures to curb the spread of COVID-19.\"\n",
    "sentence_example_content = sp(sentence_example)\n",
    "# Loop through all tokens that contain a NER type and print the token along with the corresponding NER type\n",
    "for token in sentence_example_content.ents:\n",
    "    print(\"\\\"\" + token.text + \"\\\" is a \" + token.label_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xqox7wZzFWnQ"
   },
   "source": [
    "**(TO DO) Q1 - 5 marks** \n",
    "\n",
    "In the text of **second document** (index 1) of our corpus of documents, find out which words are *PER* (spaCy uses the *PERSON* type, rather than *PER*), *ORG* (Organization), and *GPE* (Geopolitical Entity). You must do the following for this question:    \n",
    "a) (2 marks) Print each element in the text tagged as *PER*, *ORG*, and *GPE* along with its NER type from spaCy.     \n",
    "b) (1 mark) Is the majority of outputs correct? Provide two examples of incorrect outputs from (a).  \n",
    "c) (2 marks) Do any of the problems with the NER type predictions come from an earlier step in the NLP pipeline that is performed by spaCy? Describe the problem for two examples of your output from (a).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dihIJsozwfBY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"COVID-19\" is a PERSON\n",
      "\"the World Health Organization\" is a ORG\n",
      "\"WHO\" is a ORG\n",
      "\"the Public Health Agency\" is a ORG\n",
      "\"Canada\" is a GPE\n",
      "\"W.F. Wells\" is a PERSON\n",
      "\"the Harvard School of Public Health\" is a ORG\n",
      "\"Wells\" is a ORG\n",
      "\"Canada\" is a GPE\n",
      "\"Lydia Bourouiba\" is a PERSON\n",
      "\"the Fluid Dynamics of Disease Transmission Laboratory\" is a ORG\n",
      "\"the Massachusetts Institute of Technology\" is a ORG\n",
      "\"Bourouiba\" is a PERSON\n",
      "\"Mark Loeb\" is a PERSON\n",
      "\"McMaster University\" is a ORG\n",
      "\"RNA\" is a ORG\n",
      "\"Wuhan\" is a GPE\n",
      "\"China\" is a GPE\n",
      "\"Nebraska\" is a GPE\n",
      "\"Canada\" is a GPE\n",
      "\"COVID-19\" is a ORG\n",
      "\"Gary Moore/CBC\" is a PERSON\n",
      "\"Allison McGeer\" is a PERSON\n",
      "\"Sinai Health\" is a ORG\n",
      "\"Toronto\" is a GPE\n",
      "\"COVID-19\" is a PERSON\n",
      "\"McGeer\" is a ORG\n",
      "\"McGeer\" is a ORG\n",
      "\"Bourouiba\" is a PERSON\n",
      "\"Bourouiba\" is a PERSON\n",
      "\"Credit Lydia Bourouiba/MIT/JAMA Networks\" is a ORG\n",
      "\"Samira Mubareka\" is a PERSON\n",
      "\"Toronto\" is a GPE\n",
      "\"Bourouiba\" is a PERSON\n",
      "\"COVID-19\" is a ORG\n",
      "\"McMaster\" is a PERSON\n",
      "\"N95\" is a ORG\n",
      "\"U.S.\" is a GPE\n",
      "\"Justin Trudeau\" is a PERSON\n",
      "\"Mubareka\" is a PERSON\n",
      "\"the New England Journal of Medicine\" is a ORG\n",
      "\"the U.S. National Institutes of Health\" is a ORG\n",
      "\"U.S. National Institutes of Health\" is a ORG\n",
      "\"COVID-19?\" is a ORG\n",
      "\"Journal of the Royal Society Interface\" is a ORG\n",
      "\"U.S.\" is a GPE\n",
      "\"Singapore\" is a GPE\n",
      "\"N95\" is a ORG\n",
      "\"Gary S. Settles\" is a PERSON\n",
      "\"Penn State University/Journal of the Royal Society Interface\" is a ORG\n",
      "\"The World Health Organization\" is a ORG\n",
      "\"Los Angeles\" is a GPE\n",
      "\"Italy\" is a GPE\n",
      "\"Austria\" is a GPE\n"
     ]
    }
   ],
   "source": [
    "# ANSWER Q1(a) - 2 marks\n",
    "# Select the second document (index 1)\n",
    "doc = df[\"text\"][1]\n",
    "# Print each PER, ORG, GPE along with its type\n",
    "doc2=sp(doc)\n",
    "for token in doc2.ents:\n",
    "    if (token.label_ == \"PERSON\" or token.label_ == \"ORG\" or token.label_ == \"GPE\"):\n",
    "        print(\"\\\"\" + token.text + \"\\\" is a \" + token.label_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2xGIPr6FWnT"
   },
   "source": [
    "**ANSWER Q1 (b) - 1 mark**   \n",
    "Majority of the outputs are correct but there are some incorrect ones such as\n",
    "   1) \"COVID-19\" is a PERSON \\\n",
    "   2) \"Credit Lydia Bourouiba/MIT/JAMA Networks\" is a ORG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdLqDPreFWnV"
   },
   "source": [
    "**ANSWER Q1 (c) - 2 marks**   \n",
    "There can be problems from the prvious steps such as in tokenization where there were problems in spereating the words due to the punctuation, an example can be Credit Lydia Bourouiba/MIT/JAMA Networks which should have been seperated but due to the puntuation it was not sepereated properly. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6ms2R-KFWnW"
   },
   "source": [
    "**PART 2 - Text Coherence and coreference chains**  \n",
    "  \n",
    "As you saw in Q1, the results of spaCy are quite good, but not perfect.  One main issue with NER (not just in spaCy but in many tools) is that the annotation is performed one entity at a time without consideration of the overall document.  \n",
    "\n",
    "But when looking a the whole document, and knowing that text is usually coherent, we can do some post-processing to spaCy's NER module and correct some mistakes.  By text being coherent, we mean, for example, that if a person is referred to with a particular name, e.g. *McGeer*, chances are that each time we see *McGeer* in the document, it is the same person.  All the mentions of *McGeer* form a coreference chain all refering to a single entity. So it is unlikely that *McGeer* would be once a person and once an organization.  This is not always true, there are numerous counter-examples, but it is a common assumption.  This idea is even the topic of an older much-cited NLP article called \"One sense per discourse\" (Gale and al. 1992). \n",
    "\n",
    "With this idea of \"one sense per discourse\", we will explore two different strategies to use text coherence to post-process the output from the spaCy NER module.  \n",
    "\n",
    "The first strategy (*explored in Q2/Q3*) is to find, among all NER types assigned, which is the most frequent one.  For example, the name *Bourouiba* was assigned 1 time ORG, and 2 times PERSON, so this information can be used to modify the ORG type and change it to PERSON.  \n",
    "\n",
    "The second strategy (explored in Q4) is to try to find a longer surface form in the text.  Since that longer form should be less ambiguous, we can use it to disambiguate the shorter, more ambiguous forms.  For example, *Lydia Bourouiba* occurs in the text and is assigned PERSON.  We can use that information to assign further occurrences of the short form *Bourouiba* to also be PERSON.   \n",
    "\n",
    "Of course, using these methods for text coherence will not work every time, and will unfortunately introduce some errors...  But let's try.  That's what empirical studies are about, we try ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3OxLM3lAG6Y"
   },
   "source": [
    "Let's take again the news article from Q1, but this time, let's show not only GPE, PER, ORG, but rather all the Named Entities found by spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "x0W3WTdrFWnZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: \"weekly\" is a DATE\n",
      "1: \"Saturday\" is a DATE\n",
      "2: \"morning\" is a TIME\n",
      "3: \"two metres\" is a QUANTITY\n",
      "4: \"COVID-19\" is a PERSON\n",
      "5: \"the World Health Organization\" is a ORG\n",
      "6: \"WHO\" is a ORG\n",
      "7: \"more than one metre\" is a QUANTITY\n",
      "8: \"the Public Health Agency\" is a ORG\n",
      "9: \"Canada\" is a GPE\n",
      "10: \"at least two metres\" is a QUANTITY\n",
      "11: \"two\" is a CARDINAL\n",
      "12: \"2 metres\" is a QUANTITY\n",
      "13: \"the 19th century\" is a DATE\n",
      "14: \"1934\" is a DATE\n",
      "15: \"W.F. Wells\" is a PERSON\n",
      "16: \"the Harvard School of Public Health\" is a ORG\n",
      "17: \"two metres\" is a QUANTITY\n",
      "18: \"Wells\" is a ORG\n",
      "19: \"56,000\" is a CARDINAL\n",
      "20: \"Canada\" is a GPE\n",
      "21: \"Saturday\" is a DATE\n",
      "22: \"Lydia Bourouiba\" is a PERSON\n",
      "23: \"the Fluid Dynamics of Disease Transmission Laboratory\" is a ORG\n",
      "24: \"the Massachusetts Institute of Technology\" is a ORG\n",
      "25: \"Bourouiba\" is a PERSON\n",
      "26: \"Canadian\" is a NORP\n",
      "27: \"Mark Loeb\" is a PERSON\n",
      "28: \"McMaster University\" is a ORG\n",
      "29: \"RNA\" is a ORG\n",
      "30: \"Wuhan\" is a GPE\n",
      "31: \"China\" is a GPE\n",
      "32: \"Nebraska\" is a GPE\n",
      "33: \"Canada\" is a GPE\n",
      "34: \"at least two metres\" is a CARDINAL\n",
      "35: \"COVID-19\" is a ORG\n",
      "36: \"Gary Moore/CBC\" is a PERSON\n",
      "37: \"Allison McGeer\" is a PERSON\n",
      "38: \"Sinai Health\" is a ORG\n",
      "39: \"Toronto\" is a GPE\n",
      "40: \"COVID-19\" is a PERSON\n",
      "41: \"hundreds\" is a CARDINAL\n",
      "42: \"hours\" is a TIME\n",
      "43: \"N-95\" is a PRODUCT\n",
      "44: \"McGeer\" is a ORG\n",
      "45: \"five minutes\" is a TIME\n",
      "46: \"McGeer\" is a ORG\n",
      "47: \"Bourouiba\" is a PERSON\n",
      "48: \"Bourouiba\" is a PERSON\n",
      "49: \"farther than two metres\" is a QUANTITY\n",
      "50: \"seven or eight metres\" is a QUANTITY\n",
      "51: \"Credit Lydia Bourouiba/MIT/JAMA Networks\" is a ORG\n",
      "52: \"Canadian\" is a NORP\n",
      "53: \"about one kilometre\" is a QUANTITY\n",
      "54: \"two-metre\" is a QUANTITY\n",
      "55: \"up to three minutes\" is a TIME\n",
      "56: \"Samira Mubareka\" is a PERSON\n",
      "57: \"Sunnybrook Hospital\" is a FAC\n",
      "58: \"Toronto\" is a GPE\n",
      "59: \"2-metre\" is a QUANTITY\n",
      "60: \"Bourouiba\" is a PERSON\n",
      "61: \"two metres\" is a QUANTITY\n",
      "62: \"March\" is a DATE\n",
      "63: \"farther than two metres\" is a QUANTITY\n",
      "64: \"two metres\" is a QUANTITY\n",
      "65: \"Mubareka\" is a PRODUCT\n",
      "66: \"two-metre\" is a QUANTITY\n",
      "67: \"Second\" is a ORDINAL\n",
      "68: \"COVID-19\" is a ORG\n",
      "69: \"McMaster\" is a PERSON\n",
      "70: \"N95\" is a ORG\n",
      "71: \"U.S.\" is a GPE\n",
      "72: \"Canadian\" is a NORP\n",
      "73: \"Justin Trudeau\" is a PERSON\n",
      "74: \"Mubareka\" is a PERSON\n",
      "75: \"April 2020\" is a DATE\n",
      "76: \"the New England Journal of Medicine\" is a ORG\n",
      "77: \"the U.S. National Institutes of Health\" is a ORG\n",
      "78: \"0:42\" is a DATE\n",
      "79: \"U.S. National Institutes of Health\" is a ORG\n",
      "80: \"less than 10\" is a CARDINAL\n",
      "81: \"COVID-19?\" is a ORG\n",
      "82: \"2009\" is a DATE\n",
      "83: \"Journal of the Royal Society Interface\" is a ORG\n",
      "84: \"2009\" is a DATE\n",
      "85: \"U.S.\" is a GPE\n",
      "86: \"Singapore\" is a GPE\n",
      "87: \"N95\" is a ORG\n",
      "88: \"Gary S. Settles\" is a PERSON\n",
      "89: \"Penn State University/Journal of the Royal Society Interface\" is a ORG\n",
      "90: \"The World Health Organization\" is a ORG\n",
      "91: \"Los Angeles\" is a GPE\n",
      "92: \"Italy\" is a GPE\n",
      "93: \"Austria\" is a GPE\n",
      "94: \"Saturday\" is a DATE\n",
      "95: \"morning\" is a TIME\n"
     ]
    }
   ],
   "source": [
    "# Select document 2\n",
    "doc = df[\"text\"][1]\n",
    "# NER\n",
    "doc_sp = sp(doc)\n",
    "# Display all entities from the text along with their index in the .ents iterator and the\n",
    "# corresponding NER type\n",
    "for i, token in enumerate(doc_sp.ents):\n",
    "    print(str(i) + \": \\\"\" + token.text + \"\\\" is a \" + token.label_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOrta9wSFWna"
   },
   "source": [
    "**(TO DO) Q2 - 3 marks**  \n",
    "As you can see in the results, sometimes the same entity was assigned different entity types (e.g. *McGeer* is one time assigned entity type ORG, and one time entity type PERSON) since the NER algorithm looks sentence by sentence.  In the following function, the purpose will be to find all the possible entity types assigned to a single entity.\n",
    "\n",
    "Complete the definition of the *find_entity_types* function below. This function accepts as input a specific spaCy entity defined by the *entity* parameter and a list of all spaCy entities defined by the *entities* parameter.     \n",
    "\n",
    "The function must find all entities (from *entities*) having the same surface form as *entity*. For each match between the entities, add the NER type to the dictionary *type_counts* and track the number of times each NER type appears.     \n",
    "\n",
    "The *type_counts* dictionary would contain for example *McGeer* with ORG = 1, and PERSON = 1, because the function found 2 mentions of *McGeer*, each with a different type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "HJpTPmVFKFX6"
   },
   "outputs": [],
   "source": [
    "# ANSWER Q2 \n",
    "def find_entity_types(entity, entities):\n",
    "    '''\n",
    "    Given a specific entity and a list of entities, finds all entities from the list that match surface form of the specified\n",
    "    entity, but that could be of a different type.\n",
    "    \n",
    "    Returns the different NER types that have been classified for an entity and the count per NER type\n",
    "    as a dictionary with the keys as the NER type and the value as the count\n",
    "    '''\n",
    "    type_counts = { }\n",
    "    for token in entities:\n",
    "        if(token.text== entity.text):\n",
    "            if(token.label_ in type_counts):\n",
    "                type_counts[token.label_]+=1\n",
    "            else:\n",
    "                type_counts[token.label_]=1\n",
    "        \n",
    "    return type_counts  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "sAAegCdKFWnd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All possible NER types for \"2-metre\" are {'QUANTITY': 1}\n"
     ]
    }
   ],
   "source": [
    "# Test the above to find the result when checking for the types of the entity 'Bourouiba' \n",
    "# from the document loaded above\n",
    "print(\"All possible NER types for \\\"\" + doc_sp.ents[59].text + \"\\\" are \" + str(find_entity_types(doc_sp.ents[59], doc_sp.ents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7sqQ1J3FWne"
   },
   "source": [
    "**(TO DO) Q3 - 2 marks**  \n",
    "In the previous method, *find_entity_types*, we found all the possible entity types for a single entity.  Now, we want to use these to find the most common type.  For example, in the case of *McGeer*, it's a tie.  But for *Bourouiba*, there is one ORG type, and 2 PERSON type, so the most common would be PERSON.\n",
    "\n",
    "Complete the definition of the *most_common_type* function below. This function accepts as input a specific spaCy entity defined by the *entity* parameter and a list of all spaCy entities defined by the *entities* parameter.        \n",
    "\n",
    "Note: You can handle ties as you please.  Also, make sure to use the function *find_entity_types* which you just wrote in Q2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PsDxlZDzKlG1"
   },
   "outputs": [],
   "source": [
    "# ANSWER Q3 \n",
    "def most_common_type(entity, entities):\n",
    "    '''\n",
    "    Given a specific entity and a list of entities, find the most similar entities and assign the\n",
    "    NER type to entity based on the most common NER type assigned to entities of the same name (if there\n",
    "    is a tie, you decide how to handle this).\n",
    "    \n",
    "    Returns the most common NER type based on similar entities\n",
    "    '''\n",
    "    type_counts = find_entity_types(entity, entities)\n",
    "        \n",
    "    return max(type_counts, key=type_counts.get)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zwMP6IXrFWnf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common NER type to \"Bourouiba\" is PERSON\n"
     ]
    }
   ],
   "source": [
    "# Test the above to find the result when checking for the types of the entity 'Bourouiba' \n",
    "# from the document loaded above\n",
    "print(\"The most common NER type to \\\"\" + doc_sp.ents[47].text + \"\\\" is \" + most_common_type(doc_sp.ents[47], doc_sp.ents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUSoHaJXHLYS"
   },
   "source": [
    "\n",
    "Our first exploration (in Q2/Q3) was about frequency of occurrence.  We assumed the most common entity type could be the correct one.  Now, we'll explore the idea that the least ambiguous reference to an entity (the actual text) could be the correct one.  For example, *McGeer* is more ambiguous (shorter form) than *Allison McGeer* (longer form).  Often the longer form of reference to an entity is the least ambiguous.  But because it is long to write, we often use it sparingly in a text (perhaps only once) and then subsequent references to the same entity will use the shorter form.  For example, the text might mention *Allison McGeer* once, and then use the short form *McGeer* to refer to the same person many times in the document.\n",
    "\n",
    "In the course videos, we talked about the coreference chains. Thus, a chain contains long and short mentions, all referring to the same entity.\n",
    "\n",
    "The longer form is often referred to as the *normalized form*, and it is a form that we are likely to find in an external resource.  We'll see in part 3 of this notebook, when we do entity linking, that there is a Wikipedia entry for *Allison McGeer* that we could link to. We can consider the longer *Allison McGeer* form as the normalized form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwwNTuYvFWng"
   },
   "source": [
    "**(TO DO) Q4 (a) - 3 marks**  \n",
    " \n",
    "You must write a function that will find the longest form that can match a mention.\n",
    "\n",
    "Your function will have the same *entity* and *entities* parameters, but this time the function must assign to *entity* the NER type of another entity in the *entities* iterator, that of the longest form found.   \n",
    "\n",
    "Specifically, you must look through *entities* to find a normalized form of *entity*. In this scenario, the longest entity that contains *entity* as a substring will be considered the normalized form and should be returned.  If no longer form is found, the entity itself *entity* should be returned.\n",
    "\n",
    "Ex: *Lydia Bourouiba* is the normalized form of *Bourouiba*. Thus this entity should be returned.  But *McMaster University* is already the longest form, so if we search for a normalized form for that *entity*, the function should return *entity* itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "R64f86BuMUJa"
   },
   "outputs": [],
   "source": [
    "# ANSWER Q4(a)\n",
    "# Find the longest surface form within \"entities\" for which the surface for of \"entity\" is a substring\n",
    "def assign_normalized_form(entity, entities):\n",
    "    entityLength= len(entity.text)\n",
    "    entityText=entity.text\n",
    "    normalEntity=entity\n",
    "    for token in entities:\n",
    "        if (len(token.text)>entityLength) and (entityText in token.text) :\n",
    "            entityLength= len(token.text)\n",
    "            normalEntity= token\n",
    "    return normalEntity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgJfb4dgMgKW"
   },
   "source": [
    "Let's test the above function, assuming the candidates are only found in the previous mentions, as often a long form is given first to (e.g. *Allison McGeer*) and subsequent forms are the short forms (e.g. *McGeer*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QS9xZRjVXNGz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: \"weekly\" is a DATE  weekly  DATE\n",
      "1: \"Saturday\" is a DATE  Saturday  DATE\n",
      "2: \"morning\" is a TIME  morning  TIME\n",
      "3: \"two metres\" is a QUANTITY  two metres  QUANTITY\n",
      "4: \"COVID-19\" is a PERSON  COVID-19  PERSON\n",
      "5: \"the World Health Organization\" is a ORG  the World Health Organization  ORG\n",
      "6: \"WHO\" is a ORG  WHO  ORG\n",
      "7: \"more than one metre\" is a QUANTITY  more than one metre  QUANTITY\n",
      "8: \"the Public Health Agency\" is a ORG  the Public Health Agency  ORG\n",
      "9: \"Canada\" is a GPE  Canada  GPE\n",
      "10: \"at least two metres\" is a QUANTITY  at least two metres  QUANTITY\n",
      "11: \"two\" is a CARDINAL  two metres  QUANTITY\n",
      "12: \"2 metres\" is a QUANTITY  2 metres  QUANTITY\n",
      "13: \"the 19th century\" is a DATE  the 19th century  DATE\n",
      "14: \"1934\" is a DATE  1934  DATE\n",
      "15: \"W.F. Wells\" is a PERSON  W.F. Wells  PERSON\n",
      "16: \"the Harvard School of Public Health\" is a ORG  the Harvard School of Public Health  ORG\n",
      "17: \"two metres\" is a QUANTITY  at least two metres  QUANTITY\n",
      "18: \"Wells\" is a ORG  W.F. Wells  PERSON\n",
      "19: \"56,000\" is a CARDINAL  56,000  CARDINAL\n",
      "20: \"Canada\" is a GPE  Canada  GPE\n",
      "21: \"Saturday\" is a DATE  Saturday  DATE\n",
      "22: \"Lydia Bourouiba\" is a PERSON  Lydia Bourouiba  PERSON\n",
      "23: \"the Fluid Dynamics of Disease Transmission Laboratory\" is a ORG  the Fluid Dynamics of Disease Transmission Laboratory  ORG\n",
      "24: \"the Massachusetts Institute of Technology\" is a ORG  the Massachusetts Institute of Technology  ORG\n",
      "25: \"Bourouiba\" is a PERSON  Lydia Bourouiba  PERSON\n",
      "26: \"Canadian\" is a NORP  Canadian  NORP\n",
      "27: \"Mark Loeb\" is a PERSON  Mark Loeb  PERSON\n",
      "28: \"McMaster University\" is a ORG  McMaster University  ORG\n",
      "29: \"RNA\" is a ORG  RNA  ORG\n",
      "30: \"Wuhan\" is a GPE  Wuhan  GPE\n",
      "31: \"China\" is a GPE  China  GPE\n",
      "32: \"Nebraska\" is a GPE  Nebraska  GPE\n",
      "33: \"Canada\" is a GPE  Canada  GPE\n",
      "34: \"at least two metres\" is a CARDINAL  at least two metres  CARDINAL\n",
      "35: \"COVID-19\" is a ORG  COVID-19  ORG\n",
      "36: \"Gary Moore/CBC\" is a PERSON  Gary Moore/CBC  PERSON\n",
      "37: \"Allison McGeer\" is a PERSON  Allison McGeer  PERSON\n",
      "38: \"Sinai Health\" is a ORG  Sinai Health  ORG\n",
      "39: \"Toronto\" is a GPE  Toronto  GPE\n",
      "40: \"COVID-19\" is a PERSON  COVID-19  PERSON\n",
      "41: \"hundreds\" is a CARDINAL  hundreds  CARDINAL\n",
      "42: \"hours\" is a TIME  hours  TIME\n",
      "43: \"N-95\" is a PRODUCT  N-95  PRODUCT\n",
      "44: \"McGeer\" is a ORG  Allison McGeer  PERSON\n",
      "45: \"five minutes\" is a TIME  five minutes  TIME\n",
      "46: \"McGeer\" is a ORG  Allison McGeer  PERSON\n",
      "47: \"Bourouiba\" is a PERSON  Lydia Bourouiba  PERSON\n",
      "48: \"Bourouiba\" is a PERSON  Lydia Bourouiba  PERSON\n",
      "49: \"farther than two metres\" is a QUANTITY  farther than two metres  QUANTITY\n",
      "50: \"seven or eight metres\" is a QUANTITY  seven or eight metres  QUANTITY\n",
      "51: \"Credit Lydia Bourouiba/MIT/JAMA Networks\" is a ORG  Credit Lydia Bourouiba/MIT/JAMA Networks  ORG\n",
      "52: \"Canadian\" is a NORP  Canadian  NORP\n",
      "53: \"about one kilometre\" is a QUANTITY  about one kilometre  QUANTITY\n",
      "54: \"two-metre\" is a QUANTITY  two-metre  QUANTITY\n",
      "55: \"up to three minutes\" is a TIME  up to three minutes  TIME\n",
      "56: \"Samira Mubareka\" is a PERSON  Samira Mubareka  PERSON\n",
      "57: \"Sunnybrook Hospital\" is a FAC  Sunnybrook Hospital  FAC\n",
      "58: \"Toronto\" is a GPE  Toronto  GPE\n",
      "59: \"2-metre\" is a QUANTITY  2-metre  QUANTITY\n",
      "60: \"Bourouiba\" is a PERSON  Credit Lydia Bourouiba/MIT/JAMA Networks  ORG\n",
      "61: \"two metres\" is a QUANTITY  farther than two metres  QUANTITY\n",
      "62: \"March\" is a DATE  March  DATE\n",
      "63: \"farther than two metres\" is a QUANTITY  farther than two metres  QUANTITY\n",
      "64: \"two metres\" is a QUANTITY  farther than two metres  QUANTITY\n",
      "65: \"Mubareka\" is a PRODUCT  Samira Mubareka  PERSON\n",
      "66: \"two-metre\" is a QUANTITY  two-metre  QUANTITY\n",
      "67: \"Second\" is a ORDINAL  Second  ORDINAL\n",
      "68: \"COVID-19\" is a ORG  COVID-19  ORG\n",
      "69: \"McMaster\" is a PERSON  McMaster University  ORG\n",
      "70: \"N95\" is a ORG  N95  ORG\n",
      "71: \"U.S.\" is a GPE  U.S.  GPE\n",
      "72: \"Canadian\" is a NORP  Canadian  NORP\n",
      "73: \"Justin Trudeau\" is a PERSON  Justin Trudeau  PERSON\n",
      "74: \"Mubareka\" is a PERSON  Samira Mubareka  PERSON\n",
      "75: \"April 2020\" is a DATE  April 2020  DATE\n",
      "76: \"the New England Journal of Medicine\" is a ORG  the New England Journal of Medicine  ORG\n",
      "77: \"the U.S. National Institutes of Health\" is a ORG  the U.S. National Institutes of Health  ORG\n",
      "78: \"0:42\" is a DATE  0:42  DATE\n",
      "79: \"U.S. National Institutes of Health\" is a ORG  the U.S. National Institutes of Health  ORG\n",
      "80: \"less than 10\" is a CARDINAL  less than 10  CARDINAL\n",
      "81: \"COVID-19?\" is a ORG  COVID-19?  ORG\n",
      "82: \"2009\" is a DATE  2009  DATE\n",
      "83: \"Journal of the Royal Society Interface\" is a ORG  Journal of the Royal Society Interface  ORG\n",
      "84: \"2009\" is a DATE  2009  DATE\n",
      "85: \"U.S.\" is a GPE  the U.S. National Institutes of Health  ORG\n",
      "86: \"Singapore\" is a GPE  Singapore  GPE\n",
      "87: \"N95\" is a ORG  N95  ORG\n",
      "88: \"Gary S. Settles\" is a PERSON  Gary S. Settles  PERSON\n",
      "89: \"Penn State University/Journal of the Royal Society Interface\" is a ORG  Penn State University/Journal of the Royal Society Interface  ORG\n",
      "90: \"The World Health Organization\" is a ORG  The World Health Organization  ORG\n",
      "91: \"Los Angeles\" is a GPE  Los Angeles  GPE\n",
      "92: \"Italy\" is a GPE  Italy  GPE\n",
      "93: \"Austria\" is a GPE  Austria  GPE\n",
      "94: \"Saturday\" is a DATE  Saturday  DATE\n",
      "95: \"morning\" is a TIME  morning  TIME\n"
     ]
    }
   ],
   "source": [
    "# Testing using only the previous references as candidates\n",
    "test = df[\"text\"][1]\n",
    "# Parse the text with spaCy\n",
    "test_sp = sp(test)\n",
    "for i, token in enumerate(test_sp.ents):\n",
    "    ent = assign_normalized_form(test_sp.ents[i], test_sp.ents[0:i-1])\n",
    "    print(str(i) + \": \\\"\" + token.text + \"\\\" is a \" + token.label_ + \"  \" + ent.text + \"  \" + ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdiQSCS9MhkS"
   },
   "source": [
    "**(TO DO) Q4 (b) - 2 marks**  \n",
    "\n",
    "Do other tests without the limitation of using only longer forms mentioned before an entity (see *test_sp.ents[0:i-1]* in the code above), try searching before and after.  Or try an interval (e.g. max N entities before or after).  Explain what you tested.  Any difference?  Provide at least 2 examples of changes that you notice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Fk0pjs3M1VYx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: \"weekly\" is a DATE  weekly  DATE\n",
      "1: \"Saturday\" is a DATE  Saturday  DATE\n",
      "2: \"morning\" is a TIME  morning  TIME\n",
      "3: \"two metres\" is a QUANTITY  two metres  QUANTITY\n",
      "4: \"COVID-19\" is a PERSON  COVID-19  PERSON\n",
      "5: \"the World Health Organization\" is a ORG  the World Health Organization  ORG\n",
      "6: \"WHO\" is a ORG  WHO  ORG\n",
      "7: \"more than one metre\" is a QUANTITY  more than one metre  QUANTITY\n",
      "8: \"the Public Health Agency\" is a ORG  the Public Health Agency  ORG\n",
      "9: \"Canada\" is a GPE  Canada  GPE\n",
      "10: \"at least two metres\" is a QUANTITY  at least two metres  QUANTITY\n",
      "11: \"two\" is a CARDINAL  at least two metres  QUANTITY\n",
      "12: \"2 metres\" is a QUANTITY  2 metres  QUANTITY\n",
      "13: \"the 19th century\" is a DATE  the 19th century  DATE\n",
      "14: \"1934\" is a DATE  1934  DATE\n",
      "15: \"W.F. Wells\" is a PERSON  W.F. Wells  PERSON\n",
      "16: \"the Harvard School of Public Health\" is a ORG  the Harvard School of Public Health  ORG\n",
      "17: \"two metres\" is a QUANTITY  at least two metres  QUANTITY\n",
      "18: \"Wells\" is a ORG  W.F. Wells  PERSON\n",
      "19: \"56,000\" is a CARDINAL  56,000  CARDINAL\n",
      "20: \"Canada\" is a GPE  Canada  GPE\n",
      "21: \"Saturday\" is a DATE  Saturday  DATE\n",
      "22: \"Lydia Bourouiba\" is a PERSON  Lydia Bourouiba  PERSON\n",
      "23: \"the Fluid Dynamics of Disease Transmission Laboratory\" is a ORG  the Fluid Dynamics of Disease Transmission Laboratory  ORG\n",
      "24: \"the Massachusetts Institute of Technology\" is a ORG  the Massachusetts Institute of Technology  ORG\n",
      "25: \"Bourouiba\" is a PERSON  Lydia Bourouiba  PERSON\n",
      "26: \"Canadian\" is a NORP  Canadian  NORP\n",
      "27: \"Mark Loeb\" is a PERSON  Mark Loeb  PERSON\n",
      "28: \"McMaster University\" is a ORG  McMaster University  ORG\n",
      "29: \"RNA\" is a ORG  RNA  ORG\n",
      "30: \"Wuhan\" is a GPE  Wuhan  GPE\n",
      "31: \"China\" is a GPE  China  GPE\n",
      "32: \"Nebraska\" is a GPE  Nebraska  GPE\n",
      "33: \"Canada\" is a GPE  Canada  GPE\n",
      "34: \"at least two metres\" is a CARDINAL  at least two metres  CARDINAL\n",
      "35: \"COVID-19\" is a ORG  COVID-19  ORG\n",
      "36: \"Gary Moore/CBC\" is a PERSON  Gary Moore/CBC  PERSON\n",
      "37: \"Allison McGeer\" is a PERSON  Allison McGeer  PERSON\n",
      "38: \"Sinai Health\" is a ORG  Sinai Health  ORG\n",
      "39: \"Toronto\" is a GPE  Toronto  GPE\n",
      "40: \"COVID-19\" is a PERSON  COVID-19  PERSON\n",
      "41: \"hundreds\" is a CARDINAL  hundreds  CARDINAL\n",
      "42: \"hours\" is a TIME  hours  TIME\n",
      "43: \"N-95\" is a PRODUCT  N-95  PRODUCT\n",
      "44: \"McGeer\" is a ORG  Allison McGeer  PERSON\n",
      "45: \"five minutes\" is a TIME  five minutes  TIME\n",
      "46: \"McGeer\" is a ORG  Allison McGeer  PERSON\n",
      "47: \"Bourouiba\" is a PERSON  Credit Lydia Bourouiba/MIT/JAMA Networks  ORG\n",
      "48: \"Bourouiba\" is a PERSON  Credit Lydia Bourouiba/MIT/JAMA Networks  ORG\n",
      "49: \"farther than two metres\" is a QUANTITY  farther than two metres  QUANTITY\n",
      "50: \"seven or eight metres\" is a QUANTITY  seven or eight metres  QUANTITY\n",
      "51: \"Credit Lydia Bourouiba/MIT/JAMA Networks\" is a ORG  Credit Lydia Bourouiba/MIT/JAMA Networks  ORG\n",
      "52: \"Canadian\" is a NORP  Canadian  NORP\n",
      "53: \"about one kilometre\" is a QUANTITY  about one kilometre  QUANTITY\n",
      "54: \"two-metre\" is a QUANTITY  two-metre  QUANTITY\n",
      "55: \"up to three minutes\" is a TIME  up to three minutes  TIME\n",
      "56: \"Samira Mubareka\" is a PERSON  Samira Mubareka  PERSON\n",
      "57: \"Sunnybrook Hospital\" is a FAC  Sunnybrook Hospital  FAC\n",
      "58: \"Toronto\" is a GPE  Toronto  GPE\n",
      "59: \"2-metre\" is a QUANTITY  2-metre  QUANTITY\n",
      "60: \"Bourouiba\" is a PERSON  Credit Lydia Bourouiba/MIT/JAMA Networks  ORG\n",
      "61: \"two metres\" is a QUANTITY  farther than two metres  QUANTITY\n",
      "62: \"March\" is a DATE  March  DATE\n",
      "63: \"farther than two metres\" is a QUANTITY  farther than two metres  QUANTITY\n",
      "64: \"two metres\" is a QUANTITY  farther than two metres  QUANTITY\n",
      "65: \"Mubareka\" is a PRODUCT  Samira Mubareka  PERSON\n",
      "66: \"two-metre\" is a QUANTITY  two-metre  QUANTITY\n",
      "67: \"Second\" is a ORDINAL  Second  ORDINAL\n",
      "68: \"COVID-19\" is a ORG  COVID-19  ORG\n",
      "69: \"McMaster\" is a PERSON  McMaster University  ORG\n",
      "70: \"N95\" is a ORG  N95  ORG\n",
      "71: \"U.S.\" is a GPE  U.S.  GPE\n",
      "72: \"Canadian\" is a NORP  Canadian  NORP\n",
      "73: \"Justin Trudeau\" is a PERSON  Justin Trudeau  PERSON\n",
      "74: \"Mubareka\" is a PERSON  Samira Mubareka  PERSON\n",
      "75: \"April 2020\" is a DATE  April 2020  DATE\n",
      "76: \"the New England Journal of Medicine\" is a ORG  the New England Journal of Medicine  ORG\n",
      "77: \"the U.S. National Institutes of Health\" is a ORG  the U.S. National Institutes of Health  ORG\n",
      "78: \"0:42\" is a DATE  0:42  DATE\n",
      "79: \"U.S. National Institutes of Health\" is a ORG  the U.S. National Institutes of Health  ORG\n",
      "80: \"less than 10\" is a CARDINAL  less than 10  CARDINAL\n",
      "81: \"COVID-19?\" is a ORG  COVID-19?  ORG\n",
      "82: \"2009\" is a DATE  2009  DATE\n",
      "83: \"Journal of the Royal Society Interface\" is a ORG  Journal of the Royal Society Interface  ORG\n",
      "84: \"2009\" is a DATE  2009  DATE\n",
      "85: \"U.S.\" is a GPE  the U.S. National Institutes of Health  ORG\n",
      "86: \"Singapore\" is a GPE  Singapore  GPE\n",
      "87: \"N95\" is a ORG  N95  ORG\n",
      "88: \"Gary S. Settles\" is a PERSON  Gary S. Settles  PERSON\n",
      "89: \"Penn State University/Journal of the Royal Society Interface\" is a ORG  Penn State University/Journal of the Royal Society Interface  ORG\n",
      "90: \"The World Health Organization\" is a ORG  The World Health Organization  ORG\n",
      "91: \"Los Angeles\" is a GPE  Los Angeles  GPE\n",
      "92: \"Italy\" is a GPE  Italy  GPE\n",
      "93: \"Austria\" is a GPE  Austria  GPE\n",
      "94: \"Saturday\" is a DATE  Saturday  DATE\n",
      "95: \"morning\" is a TIME  morning  TIME\n"
     ]
    }
   ],
   "source": [
    "# ANSWER Q4(b)\n",
    "# Do a different test\n",
    "for i, token in enumerate(test_sp.ents):\n",
    "    ent = assign_normalized_form(test_sp.ents[i], test_sp.ents[0:i+5])\n",
    "    print(str(i) + \": \\\"\" + token.text + \"\\\" is a \" + token.label_ + \"  \" + ent.text + \"  \" + ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJ4I8-DAMvwT"
   },
   "source": [
    "**ANSWER Q4(b)**\n",
    "\n",
    "The case that was tested was taking the substring similar to the one above but now its after the substring by 5. For some of the tests the suggested normalized word had changed since it picked a longer string but that longer string had a differnt entity. This was not the desired outcome for some of these, examples of this were seen here:\n",
    "\n",
    "Examples:\\\n",
    "1)\"Bourouiba\" is a PERSON  Credit Lydia Bourouiba/MIT/JAMA Networks  ORG \\\n",
    "2)\"two\" is a CARDINAL  at least two metres  QUANTITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vxRz-qjFV9H"
   },
   "source": [
    "**(TO DO) Q5 - 5 marks**  \n",
    "Use a different news article in the corpus, the 7th article, so index 6.  \n",
    "\n",
    "(a) (2 marks) Run the two approaches (most frequent, longest form).  For each entity found in the text, print its original entity type (as found by spaCy, then the most common entity type, and then the normalized form with its entity type. \\\n",
    "(b) (3 marks) Analyze and discuss the results.  Do you think these text coherence approaches help or are they too simple?  Are there conflicting results (the two approaches give different results).  If yes, show examples that are different.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "GmyfiOEQNles"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: \"Canada\" is a GPE most common NER is GPE  Health Canada  ORG\n",
      "1: \"C.D. Howe\" is a ORG most common NER is ORG  C.D. Howe  ORG\n",
      "2: \"Ontario\" is a PERSON most common NER is PERSON  Ontario  PERSON\n",
      "3: \"Monday\" is a DATE most common NER is DATE  Monday  DATE\n",
      "4: \"Alberta\" is a GPE most common NER is GPE  Alberta  GPE\n",
      "5: \"first\" is a ORDINAL most common NER is ORDINAL  first  ORDINAL\n",
      "6: \"Saturday\" is a DATE most common NER is DATE  Saturday  DATE\n",
      "7: \"Air Canada\" is a ORG most common NER is ORG  Air Canada  ORG\n",
      "8: \"Christmas\" is a DATE most common NER is DATE  Christmas  DATE\n",
      "9: \"more than $1.2 million\" is a MONEY most common NER is MONEY  more than $1.2 million  MONEY\n",
      "10: \"England\" is a GPE most common NER is GPE  England  GPE\n",
      "11: \"Peter Cziborra/Reuters\" is a PERSON most common NER is PERSON  Peter Cziborra/Reuters  PERSON\n",
      "12: \"months\" is a DATE most common NER is DATE  months  DATE\n",
      "13: \"CBC\" is a ORG most common NER is ORG  CBC  ORG\n",
      "14: \"Andre Mayer\" is a PERSON most common NER is PERSON  Andre Mayer  PERSON\n",
      "15: \"Canada\" is a GPE most common NER is GPE  Air Canada  ORG\n",
      "16: \"19th-century\" is a DATE most common NER is DATE  19th-century  DATE\n",
      "17: \"cholera\" is a ORG most common NER is ORG  cholera  ORG\n",
      "18: \"2013\" is a DATE most common NER is DATE  2013  DATE\n",
      "19: \"Calgary\" is a GPE most common NER is GPE  Calgary  GPE\n",
      "20: \"John Brown\" is a PERSON most common NER is PERSON  John Brown  PERSON\n",
      "21: \"the University of Calgary\" is a ORG most common NER is ORG  the University of Calgary  ORG\n",
      "22: \"two-metre\" is a QUANTITY most common NER is QUANTITY  two-metre  QUANTITY\n",
      "23: \"Last week\" is a DATE most common NER is DATE  Last week  DATE\n",
      "24: \"Italian\" is a NORP most common NER is NORP  Italian  NORP\n",
      "25: \"Milan\" is a GPE most common NER is GPE  Milan  GPE\n",
      "26: \"35 kilometres\" is a QUANTITY most common NER is QUANTITY  35 kilometres  QUANTITY\n",
      "27: \"Berlin\" is a GPE most common NER is GPE  Berlin  GPE\n",
      "28: \"Budapest\" is a GPE most common NER is GPE  Budapest  GPE\n",
      "29: \"Mexico City\" is a GPE most common NER is GPE  Mexico City  GPE\n",
      "30: \"Ahsan Habib\" is a PERSON most common NER is PERSON  Ahsan Habib  PERSON\n",
      "31: \"Dalhousie University\" is a ORG most common NER is ORG  Dalhousie University  ORG\n",
      "32: \"U.S.\" is a GPE most common NER is GPE  U.S.  GPE\n",
      "33: \"Atlanta\" is a GPE most common NER is GPE  Atlanta  GPE\n",
      "34: \"Chicago\" is a GPE most common NER is GPE  Chicago  GPE\n",
      "35: \"Denver\" is a GPE most common NER is GPE  Denver  GPE\n",
      "36: \"Habib\" is a PERSON most common NER is PERSON  Ahsan Habib  PERSON\n",
      "37: \"Brown\" is a PERSON most common NER is PERSON  John Brown  PERSON\n",
      "38: \"Calgary\" is a GPE most common NER is GPE  the University of Calgary  ORG\n",
      "39: \"Housebrand\" is a ORG most common NER is ORG  Housebrand  ORG\n",
      "40: \"The National The At\" is a WORK_OF_ART most common NER is WORK_OF_ART  The National The At  WORK_OF_ART\n",
      "41: \"Quebec\" is a GPE most common NER is GPE  Quebec  GPE\n",
      "42: \"Conservative\" is a NORP most common NER is NORP  Conservative  NORP\n",
      "43: \"Canada\" is a GPE most common NER is GPE  Air Canada  ORG\n",
      "44: \"C.D. Howe\" is a ORG most common NER is ORG  C.D. Howe  ORG\n",
      "45: \"Canada\" is a GPE most common NER is GPE  Air Canada  ORG\n",
      "46: \"the C.D. Howe Institute's\" is a ORG most common NER is ORG  the C.D. Howe Institute's  ORG\n",
      "47: \"Business Cycle Council\" is a ORG most common NER is ORG  Business Cycle Council  ORG\n",
      "48: \"today\" is a DATE most common NER is DATE  today  DATE\n",
      "49: \"Canada\" is a GPE most common NER is GPE  Air Canada  ORG\n",
      "50: \"February\" is a DATE most common NER is DATE  February  DATE\n",
      "51: \"one\" is a CARDINAL most common NER is CARDINAL  one  CARDINAL\n",
      "52: \"two\" is a CARDINAL most common NER is CARDINAL  two-metre  QUANTITY\n",
      "53: \"three-month\" is a DATE most common NER is DATE  three-month  DATE\n",
      "54: \"less than two months old\" is a DATE most common NER is DATE  less than two months old  DATE\n",
      "55: \"Canada\" is a GPE most common NER is GPE  Air Canada  ORG\n",
      "56: \"first\" is a ORDINAL most common NER is ORDINAL  first  ORDINAL\n",
      "57: \"Canada\" is a GPE most common NER is GPE  Air Canada  ORG\n",
      "58: \"2008\" is a DATE most common NER is DATE  2008  DATE\n",
      "59: \"March\" is a DATE most common NER is DATE  March  DATE\n",
      "60: \"April\" is a DATE most common NER is DATE  April  DATE\n",
      "61: \"the entire month\" is a DATE most common NER is DATE  the entire month  DATE\n",
      "62: \"Canada\" is a GPE most common NER is GPE  Air Canada  ORG\n",
      "63: \"Monday\" is a DATE most common NER is DATE  Monday  DATE\n",
      "64: \"Alberta\" is a GPE most common NER is GPE  Alberta  GPE\n",
      "65: \"Saturday\" is a DATE most common NER is DATE  Saturday  DATE\n",
      "66: \"today\" is a DATE most common NER is DATE  today  DATE\n",
      "67: \"Monday\" is a DATE most common NER is DATE  Monday  DATE\n",
      "68: \"Today\" is a DATE most common NER is DATE  Today  DATE\n",
      "69: \"Doug Ford\" is a PERSON most common NER is PERSON  Doug Ford  PERSON\n",
      "70: \"Alberta\" is a GPE most common NER is GPE  Alberta  GPE\n",
      "71: \"Jason Kenney\" is a PERSON most common NER is PERSON  Jason Kenney  PERSON\n",
      "72: \"first\" is a ORDINAL most common NER is ORDINAL  first  ORDINAL\n",
      "73: \"Alberta\" is a GPE most common NER is GPE  Alberta  GPE\n",
      "74: \"Saturday\" is a DATE most common NER is DATE  Saturday  DATE\n",
      "75: \"mid-May.\" is a DATE most common NER is DATE  mid-May.  DATE\n",
      "76: \"Kenney\" is a ORG most common NER is ORG  Jason Kenney  PERSON\n",
      "77: \"Thursday\" is a DATE most common NER is DATE  Thursday  DATE\n",
      "78: \"Monday\" is a DATE most common NER is DATE  Monday  DATE\n",
      "79: \"the academic year\" is a DATE most common NER is DATE  the academic year  DATE\n",
      "80: \"Kenney\" is a ORG most common NER is ORG  Jason Kenney  PERSON\n",
      "81: \"summer\" is a DATE most common NER is DATE  summer  DATE\n",
      "82: \"Canada\" is a GPE most common NER is GPE  Air Canada  ORG\n",
      "83: \"Christmas\" is a DATE most common NER is DATE  Christmas  DATE\n",
      "84: \"Air Canada\" is a ORG most common NER is ORG  Air Canada  ORG\n",
      "85: \"Canadians\" is a NORP most common NER is NORP  Canadians  NORP\n",
      "86: \"Tim Strauss\" is a PERSON most common NER is PERSON  Tim Strauss  PERSON\n",
      "87: \"Canadian\" is a NORP most common NER is NORP  Canadians  NORP\n",
      "88: \"Air Canada\" is a ORG most common NER is ORG  Air Canada  ORG\n",
      "89: \"more than\" is a CARDINAL most common NER is CARDINAL  more than $1.2 million  MONEY\n",
      "90: \"Canadian Club Toronto\" is a ORG most common NER is ORG  Canadian Club Toronto  ORG\n",
      "91: \"today\" is a DATE most common NER is DATE  today  DATE\n",
      "92: \"North American\" is a NORP most common NER is NORP  North American  NORP\n",
      "93: \"Air Canada\" is a ORG most common NER is ORG  Air Canada  ORG\n",
      "94: \"Sunwing and American Airlines\" is a ORG most common NER is ORG  Sunwing and American Airlines  ORG\n",
      "95: \"Canada\" is a GPE most common NER is GPE  Air Canada  ORG\n",
      "96: \"two metres\" is a QUANTITY most common NER is QUANTITY  two metres  QUANTITY\n",
      "97: \"Air Canada\" is a ORG most common NER is ORG  Air Canada  ORG\n",
      "98: \"Christmas\" is a DATE most common NER is DATE  Christmas  DATE\n",
      "99: \"Helane Becker\" is a PERSON most common NER is PERSON  Helane Becker  PERSON\n",
      "100: \"first\" is a ORDINAL most common NER is ORDINAL  first  ORDINAL\n",
      "101: \"Becker\" is a PERSON most common NER is PERSON  Helane Becker  PERSON\n",
      "102: \"Canada\" is a GPE most common NER is GPE  Air Canada  ORG\n",
      "103: \"CBC News\" is a ORG most common NER is ORG  CBC News  ORG\n",
      "104: \"U.S.\" is a GPE most common NER is GPE  U.S.  GPE\n",
      "105: \"U.S.\" is a GPE most common NER is GPE  U.S.  GPE\n",
      "106: \"Anthony Fauci\" is a PERSON most common NER is PERSON  Anthony Fauci  PERSON\n",
      "107: \"Canada\" is a GPE most common NER is GPE  Air Canada  ORG\n",
      "108: \"Canada\" is a GPE most common NER is GPE  Air Canada  ORG\n",
      "109: \"Health Canada\" is a ORG most common NER is ORG  Health Canada  ORG\n",
      "110: \"Gilead\" is a ORG most common NER is ORG  Gilead  ORG\n",
      "111: \"CBC News\" is a ORG most common NER is ORG  CBC News  ORG\n",
      "112: \"Gilead\" is a ORG most common NER is ORG  Gilead  ORG\n",
      "113: \"Canada\" is a GPE most common NER is GPE  Health Canada  ORG\n",
      "114: \"Alberta\" is a GPE most common NER is GPE  Alberta  GPE\n",
      "115: \"daily\" is a DATE most common NER is DATE  daily  DATE\n",
      "116: \"Grace Horsfall Couldwell\" is a PERSON most common NER is PERSON  Grace Horsfall Couldwell  PERSON\n",
      "117: \"daily\" is a DATE most common NER is DATE  daily  DATE\n",
      "118: \"Alberta\" is a GPE most common NER is GPE  Alberta  GPE\n",
      "119: \"MJ Stead\" is a PERSON most common NER is PERSON  MJ Stead  PERSON\n",
      "120: \"Lori Toma\" is a PERSON most common NER is PERSON  Lori Toma  PERSON\n",
      "121: \"Nancy Horsfall Couldwell\" is a PERSON most common NER is PERSON  Nancy Horsfall Couldwell  PERSON\n",
      "122: \"Cochrane\" is a ORG most common NER is ORG  Cochrane  ORG\n",
      "123: \"Alta\" is a ORG most common NER is ORG  Alta  ORG\n",
      "124: \"MJ Stead\" is a PERSON most common NER is PERSON  MJ Stead  PERSON\n",
      "125: \"Facebook\" is a PRODUCT most common NER is PRODUCT  Facebook  PRODUCT\n",
      "126: \"Stead\" is a PERSON most common NER is PERSON  MJ Stead  PERSON\n",
      "127: \"hour-long\" is a TIME most common NER is TIME  hour-long  TIME\n",
      "128: \"Facebook Live\" is a PRODUCT most common NER is PRODUCT  Facebook Live  PRODUCT\n",
      "129: \"20\" is a CARDINAL most common NER is CARDINAL  2013  DATE\n",
      "130: \"30\" is a CARDINAL most common NER is CARDINAL  30  CARDINAL\n",
      "131: \"more than 1,500\" is a CARDINAL most common NER is CARDINAL  more than 1,500  CARDINAL\n",
      "132: \"more than one\" is a CARDINAL most common NER is CARDINAL  more than one  CARDINAL\n",
      "133: \"Two years ago\" is a DATE most common NER is DATE  Two years ago  DATE\n",
      "134: \"Stead\" is a PERSON most common NER is PERSON  MJ Stead  PERSON\n",
      "135: \"100 days\" is a DATE most common NER is DATE  100 days  DATE\n",
      "136: \"COVID-19\" is a ORG most common NER is ORG  COVID-19  ORG\n",
      "137: \"Canada\" is a GPE most common NER is GPE  Health Canada  ORG\n",
      "138: \"CBC News\" is a ORG most common NER is ORG  CBC News  ORG\n",
      "139: \"daily\" is a DATE most common NER is DATE  daily  DATE\n",
      "140: \"CBC News Network\" is a ORG most common NER is ORG  CBC News Network  ORG\n",
      "141: \"CBC News Network\" is a ORG most common NER is ORG  CBC News Network  ORG\n",
      "142: \"CBC\" is a ORG most common NER is ORG  CBC News Network  ORG\n",
      "143: \"CBC News Network\" is a ORG most common NER is ORG  CBC News Network  ORG\n",
      "144: \"CBC News\" is a ORG most common NER is ORG  CBC News Network  ORG\n",
      "145: \"NaN\" is a DATE most common NER is DATE  NaN  DATE\n"
     ]
    }
   ],
   "source": [
    "# ANSWER Q5(a) \n",
    "# Select document index 6\n",
    "doc = df[\"text\"][6]\n",
    "test=sp(doc)\n",
    "for i, token in enumerate(test.ents):\n",
    "    mostCommonEnt=most_common_type(test.ents[i], test.ents)\n",
    "    entity= assign_normalized_form(test.ents[i], test.ents[0:i-1])\n",
    "    print(str(i) + \": \\\"\" + token.text + \"\\\" is a \" +token.label_+\" most common NER is \"+ mostCommonEnt +  \"  \" + entity.text + \"  \" + entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "og4zSpa7NszW"
   },
   "source": [
    "**ANSWER Q5(b)**\n",
    "I believe that this approach is a bit too simple, as can be seen from the results the algorithm looks at the token itself nad the context its used in but no external information is able to be found from this approach.There were also some conflicting results as the toke alone was one entitity but the normalized form of the token gave a diferent entity. For example \\\n",
    "\n",
    "1)52: \"two\" is a CARDINAL most common NER is CARDINAL  two-metre  QUANTITY \\\n",
    "2)0: \"Canada\" is a GPE most common NER is GPE  Health Canada  ORG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ggMVG4w0FWnn"
   },
   "source": [
    "**PART 3 - Entity Linking / Text enhancement**  \n",
    "\n",
    "For the third part of this notebook, we will be exploring how we can enhance the text of documents. In this scenario, we will be enhancing the text by performing entity linking. This means that we will attempt the linking of the entities that are detected by spaCy's NER to an active webpage that a reader can click on to obtain more information regarding the entity. Wikipedia, is a very good resource to find out more information about an entity, and we will use this resource for entity linking.    \n",
    "\n",
    "Before going straight into an example through code, below is an example of how a text with no entity linking compares to a text with entity linking:    \n",
    "\n",
    "*No entity linking:* \\\n",
    "During the pandemic, U.S. cities such as Atlanta, Chicago and Denver have made several adjustments to their transit systems.      \n",
    "\n",
    "*With entity linking:*  \\    \n",
    "During the pandemic, U.S. cities such as <a href=\"http://en.wikipedia.org/wiki/Atlanta\">Atlanta</a>, <a href=\"http://en.wikipedia.org/wiki/Chicago\">Chicago</a> and <a href=\"http://en.wikipedia.org/wiki/Denver\">Denver</a> have made several adjustments to their transit systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yI7vwW2QQl0X"
   },
   "source": [
    "Transforming a text automatically with clickable links requires several processing at the character string level. In this Notebook, we will be satisfied with finding the links without making the replacements directly in the text. This will allow us to explore the Wikipedia resource, and understand the difficulties relating to \"entity linking\" without wasting too much time in the complex manipulation of strings.\n",
    "\n",
    "For example, with the document (index 6), we would like to be able to link the entities found by spaCy to the most likely wikipedia page giving access to additional information on that entity.\n",
    "\n",
    "**This enriched list format shown is the type of output requested in question Q6 below.**  For coding simplicity, we will use this type of output instead of an article in which the text would replaced by links.\n",
    "\n",
    "0: \"Coronavirus Brief\" is a ORG found at http://en.wikipedia.org/wiki/Coronavirus_Brief \\\n",
    "1: \"CBC\" is a ORG found at http://en.wikipedia.org/wiki/CBC \\\n",
    "2: \"Canada\" is a GPE found at http://en.wikipedia.org/wiki/Canada \\\n",
    "3: \"C.D. Howe\" is a PERSON found at http://en.wikipedia.org/wiki/C.D._Howe \\\n",
    "4: ... \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwS1R0ZrFWnp"
   },
   "source": [
    "**(TO DO) Q6 - 5 marks**  \n",
    "Write the code needed to search a wikipedia page for the entities found by spaCy (as shown above) in a particular document.  \n",
    "\n",
    "*You can write the code as you like, but it must include the following elements:*\n",
    "\n",
    "*   (a) A restriction on which type of entities you are linking.  For example, Wikipedia does not contain quantities (such as \"two meters\") so it would be inappropriate to include a link to a quantity.\n",
    "*   (b) The use of the *normalized form* of the entity to perform the linking.  For example, *Allison McGeer* does have a Wikipedia page (https://en.wikipedia.org/wiki/Allison_McGeer) that you can link to, even when you are looking at the entity with label *McGeer*.  So make sure to use the function you developed in Q4.\n",
    "*   (c) Attention:  the wikipedia page uses underscores. So for example, *McMaster University* should be transformed to https://en.wikipedia.org/wiki/McMaster_University (with an underscore between *McMaster* and *University*\n",
    "*   (d) Include one element of post-processing on the longer form.  For example *the C.D. Howe Institute's* is tagged by spaCy, but Wikipedia will contain *C.D._Howe_Institute*.  You can remove small particules like *the* to augment the chance of linking.\n",
    "*   (e) For a specific document, output the surface form, entity type and link to Wikipedia in a list as shown above\n",
    "\n",
    "Be sure to put comments in your code to make it clear what corresponds to parts (a), (b), (c), (d) and (e).\n",
    "\n",
    "There will be probably many links that you include that will link to wikipedia pages that do not exist.  That's ok, don't worry about that.  Wikipedia does not contain everything, and some normalized forms will not be there.  You will be asked to discuss this later in Q7.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "iquX3GDvRswP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: \"U.S.\" is a GPE\" the link is: https://en.wikipedia.org/wiki/U.S.\n",
      "1: \"Thursday\" is a DATE\" the link is: https://en.wikipedia.org/wiki/Thursday\n",
      "2: \"Chinese\" is a NORP\" the link is: https://en.wikipedia.org/wiki/Chinese\n",
      "3: \"the Office of the Director of National Intelligence\" is a ORG\" the link is: https://en.wikipedia.org/wiki/Office_of_Director_of_National_Intelligence\n",
      "4: \"U.S.\" is a GPE\" the link is: https://en.wikipedia.org/wiki/U.S.\n",
      "5: \"U.S.\" is a GPE\" the link is: https://en.wikipedia.org/wiki/U.S.\n",
      "6: \"Donald Trump\" is a PERSON\" the link is: https://en.wikipedia.org/wiki/Donald_Trump\n",
      "8: \"Wuhan\" is a GPE\" the link is: https://en.wikipedia.org/wiki/Wuhan\n",
      "9: \"Chinese\" is a NORP\" the link is: https://en.wikipedia.org/wiki/Chinese\n",
      "11: \"recent days\" is a DATE\" the link is: https://en.wikipedia.org/wiki/recent_days\n",
      "12: \"Trump\" is a PERSON\" the link is: https://en.wikipedia.org/wiki/Donald_Trump\n",
      "13: \"China\" is a GPE\" the link is: https://en.wikipedia.org/wiki/China\n",
      "15: \"IC\" is a ORG\" the link is: https://en.wikipedia.org/wiki/IC\n",
      "16: \"Wuhan\" is a GPE\" the link is: https://en.wikipedia.org/wiki/Wuhan\n",
      "17: \"COVID-19\" is a PERSON\" the link is: https://en.wikipedia.org/wiki/COVID-19\n",
      "18: \"China\" is a GPE\" the link is: https://en.wikipedia.org/wiki/China\n",
      "19: \"State\" is a ORG\" the link is: https://en.wikipedia.org/wiki/State\n",
      "20: \"Mike Pompeo\" is a PERSON\" the link is: https://en.wikipedia.org/wiki/Mike_Pompeo\n",
      "21: \"Thursday\" is a DATE\" the link is: https://en.wikipedia.org/wiki/Thursday\n",
      "22: \"U.S.\" is a GPE\" the link is: https://en.wikipedia.org/wiki/U.S.\n",
      "23: \"Russian\" is a NORP\" the link is: https://en.wikipedia.org/wiki/Russian\n",
      "24: \"2016\" is a DATE\" the link is: https://en.wikipedia.org/wiki/2016\n",
      "25: \"Thursday\" is a DATE\" the link is: https://en.wikipedia.org/wiki/Thursday\n",
      "26: \"the White House\" is a ORG\" the link is: https://en.wikipedia.org/wiki/White_House\n",
      "27: \"Pompeo\" is a PERSON\" the link is: https://en.wikipedia.org/wiki/Mike_Pompeo\n",
      "28: \"China\" is a GPE\" the link is: https://en.wikipedia.org/wiki/China\n",
      "29: \"Trump and Pompeo\" is a ORG\" the link is: https://en.wikipedia.org/wiki/Trump_and_Pompeo\n",
      "30: \"U.S.\" is a GPE\" the link is: https://en.wikipedia.org/wiki/U.S.\n",
      "31: \"Senate\" is a ORG\" the link is: https://en.wikipedia.org/wiki/Senate\n",
      "32: \"Dan Coats\" is a PERSON\" the link is: https://en.wikipedia.org/wiki/Dan_Coats\n",
      "33: \"last year\" is a DATE\" the link is: https://en.wikipedia.org/wiki/last_year\n",
      "34: \"Joseph Maguire\" is a PERSON\" the link is: https://en.wikipedia.org/wiki/Joseph_Maguire\n",
      "35: \"Richard Grenell\" is a PERSON\" the link is: https://en.wikipedia.org/wiki/Richard_Grenell\n",
      "36: \"John Ratcliffe\" is a PERSON\" the link is: https://en.wikipedia.org/wiki/John_Ratcliffe\n",
      "37: \"Texas\" is a GPE\" the link is: https://en.wikipedia.org/wiki/Texas\n",
      "39: \"Trump\" is a ORG\" the link is: https://en.wikipedia.org/wiki/Trump_and_Pompeo\n",
      "40: \"Coats\" is a PERSON\" the link is: https://en.wikipedia.org/wiki/Dan_Coats\n",
      "41: \"Senate\" is a ORG\" the link is: https://en.wikipedia.org/wiki/Senate\n",
      "42: \"next week\" is a DATE\" the link is: https://en.wikipedia.org/wiki/next_week\n",
      "43: \"Senate\" is a ORG\" the link is: https://en.wikipedia.org/wiki/Senate\n",
      "44: \"Pompeo\" is a PERSON\" the link is: https://en.wikipedia.org/wiki/Trump_and_Pompeo\n",
      "45: \"the Chinese Academy of Sciences\" is a ORG\" the link is: https://en.wikipedia.org/wiki/Chinese_Academy_of_Sciences\n",
      "46: \"the Wuhan Institute of Virology\" is a ORG\" the link is: https://en.wikipedia.org/wiki/Wuhan_Institute_of_Virology\n",
      "47: \"Pompeo\" is a PERSON\" the link is: https://en.wikipedia.org/wiki/Trump_and_Pompeo\n",
      "48: \"two weeks ago\" is a DATE\" the link is: https://en.wikipedia.org/wiki/two_weeks_ago\n",
      "50: \"Beijing\" is a GPE\" the link is: https://en.wikipedia.org/wiki/Beijing\n",
      "51: \"U.S.\" is a GPE\" the link is: https://en.wikipedia.org/wiki/U.S.\n",
      "52: \"the American Embassy\" is a ORG\" the link is: https://en.wikipedia.org/wiki/American_Embassy\n",
      "53: \"Beijing\" is a GPE\" the link is: https://en.wikipedia.org/wiki/Beijing\n",
      "54: \"Wuhan\" is a GPE\" the link is: https://en.wikipedia.org/wiki/Wuhan_Institute_of_Virology\n",
      "55: \"2018\" is a DATE\" the link is: https://en.wikipedia.org/wiki/2018\n",
      "56: \"nearly two years later\" is a DATE\" the link is: https://en.wikipedia.org/wiki/nearly_two_years_later\n",
      "57: \"Chinese\" is a NORP\" the link is: https://en.wikipedia.org/wiki/Chinese_Academy_of_Sciences\n",
      "58: \"Thursday\" is a DATE\" the link is: https://en.wikipedia.org/wiki/Thursday\n",
      "59: \"WHO\" is a ORG\" the link is: https://en.wikipedia.org/wiki/WHO\n",
      "60: \"DoseWhy\" is a ORG\" the link is: https://en.wikipedia.org/wiki/DoseWhy\n",
      "61: \"Foreign Ministry\" is a ORG\" the link is: https://en.wikipedia.org/wiki/Foreign_Ministry\n",
      "62: \"Geng Shuang\" is a PERSON\" the link is: https://en.wikipedia.org/wiki/Geng_Shuang\n",
      "63: \"Yuan Zhiming\" is a PERSON\" the link is: https://en.wikipedia.org/wiki/Yuan_Zhiming\n",
      "64: \"Geng\" is a PERSON\" the link is: https://en.wikipedia.org/wiki/Geng_Shuang\n",
      "65: \"Geng\" is a PERSON\" the link is: https://en.wikipedia.org/wiki/Geng_Shuang\n",
      "66: \"U.S.\" is a GPE\" the link is: https://en.wikipedia.org/wiki/U.S.\n",
      "67: \"China\" is a GPE\" the link is: https://en.wikipedia.org/wiki/China\n",
      "68: \"Chinese\" is a NORP\" the link is: https://en.wikipedia.org/wiki/Chinese_Academy_of_Sciences\n",
      "69: \"Zhao Lijian\" is a PERSON\" the link is: https://en.wikipedia.org/wiki/Zhao_Lijian\n",
      "70: \"China\" is a GPE\" the link is: https://en.wikipedia.org/wiki/China\n",
      "71: \"March\" is a DATE\" the link is: https://en.wikipedia.org/wiki/March\n",
      "72: \"the U.S. Army\" is a ORG\" the link is: https://en.wikipedia.org/wiki/U.S._Army\n"
     ]
    }
   ],
   "source": [
    "# ANSWER - Q6\n",
    "doc = df[\"text\"][12]\n",
    "spacy_doc = sp(doc)\n",
    "#validEntities=[\"DATE\"]\n",
    "#validEntities = [\"CARDINAL\"]\n",
    "#validEntities = [\"PERSON\", \"GPE\",\"ORG\"]\n",
    "validEntities=[\"PERSON\", \"GPE\", \"ORG\",\"NORP\", \"PRODUCT\", \"DATE\"]#Used for the restriction of the entities for part a)\n",
    "for i,token in enumerate(spacy_doc.ents):\n",
    "    if(token.label_ in validEntities):\n",
    "        entity= assign_normalized_form(spacy_doc.ents[i], spacy_doc.ents[0:i-1])# Finding the normalized form of the entity for b)\n",
    "        #c) adding in the underscore to the normalized form\n",
    "        linked=entity.text.split()\n",
    "        linked='_'.join(linked)\n",
    "        #d) post processing in long form\n",
    "        char_to_replace = {\"The_\": \"\", 'the_': \"\", \"'s\":\"\",\"?\":\"\",\"!\":\"\"} \n",
    "        for key, value in char_to_replace.items():\n",
    "            # Replace key character with value character in string\n",
    "            linked= linked.replace(key, value)\n",
    "        endLink='https://en.wikipedia.org/wiki/'+linked\n",
    "        #e) outputted the surface form\n",
    "        print(str(i) + \": \\\"\" + token.text + \"\\\" is a \" +token.label_+ \"\\\" the link is: \"+endLink)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0AmNbFFFWnq"
   },
   "source": [
    "**(TO DO) Q7 - 5 marks**  \n",
    "Perform a qualitative evaluation of the entity linking method you wrote in Q6.  For your qualitative evaluation, you must choose a document (any one you want from the corpus of covid-19 related news, but make sure to mention which one) and run your method on that document.  Answer the following questions : \n",
    "\n",
    "* a. Give 2 examples of entities where the longer form was found in Wikipedia.  Is the page found appropriate? Would the shorter form be found too? Would it link to the same page?  \n",
    "* b.  Give 2 examples of entities where the wikipedia page did not exist.  Why is that?  Was the form searched on incorrect?  \n",
    "* c.  Try restricting your search with different entity types.  Do you see DATE covered by Wikipedia?  What about PERSON or GPE?  Discuss the coverage of different entity types by giving some examples.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGwHrXL2SDhY"
   },
   "source": [
    "**ANSWER Q7**\\\n",
    "a)Two examples where the longform was found in wikipedia were:\\\n",
    "    1)54: \"Wuhan\" is a GPE\" the link is: https://en.wikipedia.org/wiki/Wuhan_Institute_of_Virology \\\n",
    "    2)27: \"Pompeo\" is a PERSON\" the link is: https://en.wikipedia.org/wiki/Mike_Pompeo \n",
    "    \n",
    "b)Two examples where the longform was not found in wikipedia were:\\\n",
    "    1)29: \"Trump and Pompeo\" is a ORG\" the link is: https://en.wikipedia.org/wiki/Trump_and_Pompeo this was becasue this form did not exist on wikipedia as it was the incorrect search for it.\\\n",
    "    2)56: \"nearly two years later\" is a DATE\" the link is: https://en.wikipedia.org/wiki/nearly_two_years_later this was because the form does not exist on wikipedia as it was the incorrect search for it. \n",
    "    \n",
    "c)For the DATE entity it seen that when date is the proper serach it will give information on the specifc date or time such as \"March\" however most of the DATE entitiy long forms do not have a proper wikipedia page. For PERSON, GPE and ORG it can be seen that most of the longofmrs will be provide proper wikipedia pages. It seems that entities such as \"PERSON\", \"GPE\", \"ORG\",\"NORP\", \"PRODUCT\" will give more valid wikipedia links than enitites such \"DATE\" or \"CARDINAL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnOkubO4FWnt"
   },
   "source": [
    "***SIGNATURE:***\n",
    "My name is Sy Rajeswaran.\n",
    "My student number is 300005333.\n",
    "I certify being the author of this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CSI4106_KR_Fall2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
