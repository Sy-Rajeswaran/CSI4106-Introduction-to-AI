{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3aO38zC0-5L"
   },
   "source": [
    "# Notebook 5 - Titanic Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5U6AOch0-5M"
   },
   "source": [
    "CSI4106 Artificial Intelligence  \n",
    "Fall 2021. \\\n",
    "Version 1 (2020) prepared by Julian Templeton.  Version 2 (2021) modified by Caroline Barri√®re."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kiedO0TE0-5M"
   },
   "source": [
    "***INTRODUCTION***:\n",
    "\n",
    "The supervised classification task tackled in this notebook is to determine whether a passenger survived or did not survive on the Titanic. This is a common introductory problem to supervised machine learning and is a challenge on a popular site called Kaggle. Kaggle contains competitions that participants can compete in. These competitions typical provide a dataset to work with and a description of the problem to solve. That said, not all datasets will include the ground truth for the test set. Or, a competition may only provide a training and validation set, not the test set. This means that participants will not know how their models perform on the real unseen data until the host(s) test the participant's submission on the private test set, posting the results.    \n",
    "\n",
    "This notebook will expand your knowledge from the previous notebook and will introduce the concept of dealing with class imabalance through the use of a technique called oversampling. You will also see how a dataset can have issues with its data and that not every feature should be used to train and test a model. You will also perform the training, testing, and evaluation in slightly new ways since we will be working with a different type of dataset.\n",
    "\n",
    "Once again, this notebook uses **scikit-learn** (http://scikit-learn.org/stable/), **Matplot**, **Numpy**, and **Pandas**. Also, we will be using **imblearn** which provides robust techniques for balancing the number of instances of different classes. To install this packge, use the command ***pip install imbalanced-learn***. If this causes any issues you can also try *pip install imblearn*.  As was mentioned in the previous notebook, if a local installation of these packages creates any problem, don't hesitate to move to *colab*, an environment provided by Google in which you can run your notebooks.\n",
    "\n",
    "In this notebook we will use the Naive Bayes algorithm and the Logistic Regression algorithm to perform the binary classification of the survival of passengers on the Titanic. After evaluating both models, you will determine which performed better, and why. Finally, you will go through the process once more to determine whether or not a common oversampling technique will improve the results obtained.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1zn2uY90-5N"
   },
   "source": [
    "***HOMEWORK***:  \\\n",
    "\n",
    "Go through the notebook by running each cell, one at a time.  \n",
    "Look for **(TO DO)** for the tasks that you need to perform. Do not edit the code outside of the questions which you are asked to answer unless specifically asked. Once you're done, sign the notebook (at the end of the notebook), change its name to StudentNumber-LastName-Notebook5.ipynb and submit it.  \n",
    "\n",
    "*The notebook will be marked on 30.  \n",
    "Each **(TO DO)** has a number of points associated with it.*\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fruPKuL0-5N"
   },
   "source": [
    "**1. Exploring the dataset**    \n",
    "\n",
    "First, we will set up the data that we will be working with. This data is included with the notebook and can be found from Kaggle, which also contains a description of the data that we will be working with (https://www.kaggle.com/c/titanic/data). \n",
    "\n",
    "It is highly recommended that you ***look at the attribute descriptions*** within the Overview section that is available by the link above. This will help you understand the data that we will be working with.     \n",
    "\n",
    "As alluded to in the introduction, this Kaggle competition only provides annotated training data, while the testing data is unannotated. The ground truth of the the test dataset can be found online, but we will focus on only using the training dataset to create and test our model.       \n",
    "\n",
    "In general, a competition will only give a training set, so we will try to learn whether a passenger did or did not survive on the Titanic from this training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pO55OGYT0-5N"
   },
   "outputs": [],
   "source": [
    "# Import the required packages for data analysis and machine learning\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4bLwgb70-5O"
   },
   "source": [
    "First, we will load the training dataset (*train.csv*) into a dataframe with Pandas and explore the first ten samples. Notice that this dataset contains a variety of potential features, unlike the movie reviews that we worked with last notebook which contained movie reviews (textual form) that we had to transform. The current dataset contains both continuous and discrete values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AJbZO9gq0-5O"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset, show top ten rows\n",
    "X = pd.read_csv(\"train.csv\")\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MciBjuCz0-5O"
   },
   "source": [
    "From the above, we can see a variety of columns. Out of these columns, the ***Survived*** column represents the class values that we wish to predict. A passenger survived from the Titanic if *Survived* is 1 and did not survive from the Titanic if *Survived* is 0. These are our two classes that we will predict (1 and 0). The other columns represent potential features that can be used by the Machine Learning algorithms to learn how to accurately predict the target class.   \n",
    "\n",
    "One important note from the data above is that not every sample contains data for each column. For example, Passenger 6 (Moran, Mr. James) does not contain a value for their *Age* and does not contain the *Cabin* that they were residing in. Since Machine Learning algorithms learn from data, a Data Scientist will need to learn how to accurately fill in the missing data. Robust methods of doing this is beyond the scope of this notebook, but we will be filling in most of the missing data later on through simple means.    \n",
    "\n",
    "Another note is that it is important to consider whether one class is seen more frequently than another class within the data. A class with the most instances is called the *majority* class and a class with least instances is called the *minority* class. If one class contains more instances than another class, the algorithm may focus on learning that majority class more than the minority class. In problems such as cancer diagnosis, this is a major problem (since many more people do not have cancer). Thus, another issue that we will explore in this notebook is the concept of using oversampling  to balance the class distribution. This concept will be explained in detail later in the notebook.  \n",
    "\n",
    "Below is a plot of the number of instances for each class. In this scenario, based on the data available from the training set, more people did not survive on the Titanic than those who did survive (as we would expect in this scenario). Since we cannot simply collect more data on passenger's who survived the Titanic, we will need to think of ways to balance the class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Rnx6mn4Z0-5P"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure() # Creates a new figure\n",
    "X[\"Survived\"].value_counts().plot(kind=\"bar\", title=\"Survived Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tT9brxu60-5P"
   },
   "source": [
    "With this in mind, we will now move the class values from the pandas dataframe X into a numpy array called y. X is typically used to refer to the features and y is typically used to represent the class values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9vVgyehh0-5P"
   },
   "outputs": [],
   "source": [
    "# This can ONLY BE DONE ONCE, as we pop the values into a new variable to be used as predicted class\n",
    "y = X.pop(\"Survived\").values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FqV1kkhy0-5P"
   },
   "source": [
    "Since we have taken a look into the class distribution, we will now take a look into the other attributes available in the dataset. Below we print a list of all available attributes and explore the properties of the *Embarked* column (port where passengers embarked the Titanic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "p620peZy0-5P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
      "(891, 11)\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Show all attributes\n",
    "print(list(X))\n",
    "# Examples of data exploration\n",
    "print(X.shape)\n",
    "print(X['Embarked'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57zJRqxE0-5P"
   },
   "source": [
    "From the above result, we see that the *Embarked* attribute contains 644 *S* values, 168 *C* values, and 77 *Q* values. But this is actually two less than the total of 891 instances. Thus, there are two missing values within this attribute. We can find these instances via the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7Rzd8jtm0-5P"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>Icard, Miss. Amelie</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                       Name     Sex  \\\n",
       "61            62       1                        Icard, Miss. Amelie  female   \n",
       "829          830       1  Stone, Mrs. George Nelson (Martha Evelyn)  female   \n",
       "\n",
       "      Age  SibSp  Parch  Ticket  Fare Cabin Embarked  \n",
       "61   38.0      0      0  113572  80.0   B28      NaN  \n",
       "829  62.0      0      0  113572  80.0   B28      NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the rows with a null Embarked value\n",
    "X[X['Embarked'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWa-lQkp0-5Q"
   },
   "source": [
    "**(TO DO) Q1 - 2 marks**   \n",
    "Similarly to the above example, explore the *Age* and the *Cabin* attributes by printing which values they contain.  Note that when an attribute has too many possible values, only the first and last values will be shown (with ... in between).\n",
    "\n",
    "Also print the rows where they are missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dDWfRoY30-5Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.00    30\n",
      "22.00    27\n",
      "18.00    26\n",
      "19.00    25\n",
      "28.00    25\n",
      "         ..\n",
      "36.50     1\n",
      "55.50     1\n",
      "0.92      1\n",
      "23.50     1\n",
      "74.00     1\n",
      "Name: Age, Length: 88, dtype: int64\n",
      "     PassengerId  Pclass                                      Name     Sex  \\\n",
      "5              6       3                          Moran, Mr. James    male   \n",
      "17            18       2              Williams, Mr. Charles Eugene    male   \n",
      "19            20       3                   Masselmani, Mrs. Fatima  female   \n",
      "26            27       3                   Emir, Mr. Farred Chehab    male   \n",
      "28            29       3             O'Dwyer, Miss. Ellen \"Nellie\"  female   \n",
      "..           ...     ...                                       ...     ...   \n",
      "859          860       3                          Razi, Mr. Raihed    male   \n",
      "863          864       3         Sage, Miss. Dorothy Edith \"Dolly\"  female   \n",
      "868          869       3               van Melkebeke, Mr. Philemon    male   \n",
      "878          879       3                        Laleff, Mr. Kristo    male   \n",
      "888          889       3  Johnston, Miss. Catherine Helen \"Carrie\"  female   \n",
      "\n",
      "     Age  SibSp  Parch      Ticket     Fare Cabin Embarked  \n",
      "5    NaN      0      0      330877   8.4583   NaN        Q  \n",
      "17   NaN      0      0      244373  13.0000   NaN        S  \n",
      "19   NaN      0      0        2649   7.2250   NaN        C  \n",
      "26   NaN      0      0        2631   7.2250   NaN        C  \n",
      "28   NaN      0      0      330959   7.8792   NaN        Q  \n",
      "..   ...    ...    ...         ...      ...   ...      ...  \n",
      "859  NaN      0      0        2629   7.2292   NaN        C  \n",
      "863  NaN      8      2    CA. 2343  69.5500   NaN        S  \n",
      "868  NaN      0      0      345777   9.5000   NaN        S  \n",
      "878  NaN      0      0      349217   7.8958   NaN        S  \n",
      "888  NaN      1      2  W./C. 6607  23.4500   NaN        S  \n",
      "\n",
      "[177 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# ANSWER Q1: For the Age attribute\n",
    "print(X['Age'].value_counts())\n",
    "print(X[X['Age'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ddpShTvxFvxG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B96 B98        4\n",
      "G6             4\n",
      "C23 C25 C27    4\n",
      "C22 C26        3\n",
      "F33            3\n",
      "              ..\n",
      "E34            1\n",
      "C7             1\n",
      "C54            1\n",
      "E36            1\n",
      "C148           1\n",
      "Name: Cabin, Length: 147, dtype: int64\n",
      "     PassengerId  Pclass                                      Name     Sex  \\\n",
      "0              1       3                   Braund, Mr. Owen Harris    male   \n",
      "2              3       3                    Heikkinen, Miss. Laina  female   \n",
      "4              5       3                  Allen, Mr. William Henry    male   \n",
      "5              6       3                          Moran, Mr. James    male   \n",
      "7              8       3            Palsson, Master. Gosta Leonard    male   \n",
      "..           ...     ...                                       ...     ...   \n",
      "884          885       3                    Sutehall, Mr. Henry Jr    male   \n",
      "885          886       3      Rice, Mrs. William (Margaret Norton)  female   \n",
      "886          887       2                     Montvila, Rev. Juozas    male   \n",
      "888          889       3  Johnston, Miss. Catherine Helen \"Carrie\"  female   \n",
      "890          891       3                       Dooley, Mr. Patrick    male   \n",
      "\n",
      "      Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
      "0    22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
      "2    26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "4    35.0      0      0            373450   8.0500   NaN        S  \n",
      "5     NaN      0      0            330877   8.4583   NaN        Q  \n",
      "7     2.0      3      1            349909  21.0750   NaN        S  \n",
      "..    ...    ...    ...               ...      ...   ...      ...  \n",
      "884  25.0      0      0   SOTON/OQ 392076   7.0500   NaN        S  \n",
      "885  39.0      0      5            382652  29.1250   NaN        Q  \n",
      "886  27.0      0      0            211536  13.0000   NaN        S  \n",
      "888   NaN      1      2        W./C. 6607  23.4500   NaN        S  \n",
      "890  32.0      0      0            370376   7.7500   NaN        Q  \n",
      "\n",
      "[687 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# ANSWER Q1: For the Cabin attribute\n",
    "print(X['Cabin'].value_counts())\n",
    "print(X[X['Cabin'].isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KeWWnE20-5Q"
   },
   "source": [
    "**2. Cleaning the data**    \n",
    "\n",
    "Having explored the dataset, we will now work on cleaning some of the missing values from attributes that we will be using as features for the Machine Learning algorithms.  We will then look at discrete and continuous attributes.\n",
    "\n",
    "***2.1. Missing values***\n",
    "\n",
    "Let's fill in the missing values for the *Age* and *Embarked* attributes. Although it is also possible to do this for the *Cabin* attribute, this attribute requires additional care when filling in its missing values. Thus, this notebook will not be exploring the *Cabin* attribute despite its importance (since the location of the passenger is an important identifier as to whether they survived or did not survive).   \n",
    "\n",
    "For your own interest, the following article does a good job discussing some of the available *imputation* methods: https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4. Note that the term *imputation* refers to the process of filling in missing values. In this notebook, we will use trivial methods for imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QpEZhYem0-5Q"
   },
   "source": [
    "For the *Age* attribute, we will fill in the missing values with a trivial method. The missing values will be filled with the mean age of passengers that contain a non-null age value. Although this will likely cause issues, such as making the algorithm learn inaccurate patterns from the mean age values, this is one of many trival approaches to filling in the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "mPox2k8n0-5Q"
   },
   "outputs": [],
   "source": [
    "# Update the dataframe by filling in all missing age values as the mean of existing age values.\n",
    "X[\"Age\"].fillna(X[\"Age\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PU9ysp9V0-5Q"
   },
   "source": [
    "For the *Embarked* attribute, we will also use a trivial approach.  We will simply take a random choice between all three possibilities ('S', 'C', 'Q')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0mAjgIyH8fIh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S', 'C', 'Q']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "poss = X['Embarked'].value_counts().index.tolist()\n",
    "print(poss)\n",
    "X[\"Embarked\"].fillna(random.choice(poss), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yQvc_RC_1Oz"
   },
   "source": [
    "***2.2. Discrete/Continuous features***\n",
    "\n",
    "Before selecting which features to use, we will convert the categorical data (discrete attributes) within the *Sex* and *Embarked* columns to be numerical. This will be done via One-Hot-Encoding, where each possible categorical value for an attribute is made to be its own attribute. Then, only one of these three attributes will contain the value 1 for a row, where the others contain 0. In the next notebook we will explore the OneHotEncoder provided by sklearn, but we will handle this manually with pandas for this notebook (via the *get_dummies* function).\n",
    "\n",
    "This one-hot encoding is necessary for the logistic regression classifier (which we will use later).  We will also use a Naive Bayes classifier later which works well on discrete features, but the sklearn version allows it to work on continuous features as well, incorporating a bin-splitting (discretization).  So if all are attributes are continuous, we will be ok with both learners later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "llwkTEam0-5S"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S  \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5bGQaaoY0-5S"
   },
   "outputs": [],
   "source": [
    "# Convert the categorical values stored within the Sex column to be numerical via One-Hot-Encoding\n",
    "X = pd.concat([X, pd.get_dummies(X['Sex'], prefix='Sex')], axis=1)\n",
    "# Drop the original column\n",
    "X.drop(['Sex'], axis=1, inplace=True)\n",
    "# Convert the categorical values stored within the Embarked column to be numerical via One-Hot-Encoding\n",
    "X = pd.concat([X, pd.get_dummies(X['Embarked'], prefix='Embarked')], axis=1)\n",
    "# Drop the original column\n",
    "X.drop(['Embarked'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3uAFnN-D0-5S"
   },
   "source": [
    "Let us take a final look at the first 5 entries in our dataset. Look at how the columns differ from the output above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "V15utYAe0-5S"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "    Age  SibSp  Parch            Ticket     Fare Cabin  Sex_female  Sex_male  \\\n",
       "0  22.0      1      0         A/5 21171   7.2500   NaN           0         1   \n",
       "1  38.0      1      0          PC 17599  71.2833   C85           1         0   \n",
       "2  26.0      0      0  STON/O2. 3101282   7.9250   NaN           1         0   \n",
       "3  35.0      1      0            113803  53.1000  C123           1         0   \n",
       "4  35.0      0      0            373450   8.0500   NaN           0         1   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  \n",
       "0           0           0           1  \n",
       "1           1           0           0  \n",
       "2           0           0           1  \n",
       "3           0           0           1  \n",
       "4           0           0           1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AloMxZcg0-5S"
   },
   "source": [
    "**3. Feature selection and defining the train and validation sets**    \n",
    "\n",
    "With the data ready to be used, we will now select the features that we will be working with and define the training and validation sets from the available data. For our feature selection we will simply be selecting all non-null attributes except for the *PassengerId*, *Ticket* and *Name*.   \n",
    "\n",
    "*PassengerId* is a unique number for each passenger and therefore cannot provide any useful patterns regarding the target class values. The names (attribute (*Name*) are also unlikely to provide any insight as to whether a passenger did or did not survive.         \n",
    "\n",
    "*Ticket* is a value that does not seem to provide any useful information either. Therefore we will not use it.\n",
    "\n",
    "Let us look at the remaining attributes to see if any still contain null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "s0HOTVzG0-5S"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Sex_female       0\n",
       "Sex_male         0\n",
       "Embarked_C       0\n",
       "Embarked_Q       0\n",
       "Embarked_S       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at what is null\n",
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvwbdxvX0-5S"
   },
   "source": [
    "As we can see, all attributes except for *Cabin* contain no missing values. Although *Cabin* is important, we will exclude it since we did not properly clean it and majority of the data is missing a value. Although we can skip any rows that do not contain a *Cabin* value or can assign an 'unknown' value to missing values, there are too many missing values for this to be reasonable.    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "SRQxWCEW0-5S"
   },
   "outputs": [],
   "source": [
    "# Define the list of attributes to use as features for the algorithms.\n",
    "featureSet = ['Pclass', 'Sex_female', 'Sex_male', 'Age', 'SibSp', \n",
    "              'Parch', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "C-pEVgqK0-5S"
   },
   "outputs": [],
   "source": [
    "# Set the dataframe to only contain the desired variables\n",
    "X = X[featureSet].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7GFJvjF0-5T"
   },
   "source": [
    "With the features selected, we will now split the data into a training and validation set from the available data. Although sklearn calls the function \"train_test_split\", we know that we are dividing the original training set into a train and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "fccerth60-5T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 10)\n",
      "(179,)\n"
     ]
    }
   ],
   "source": [
    "# split the large dataset into train and test\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state=2)\n",
    "# Look at the shape of the outputs\n",
    "print(X_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "3wf2GB1V0-5T"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex_female  Sex_male   Age  SibSp  Parch     Fare  Embarked_C  \\\n",
       "30        1           0         1  40.0      0      0  27.7208           1   \n",
       "10        3           1         0   4.0      1      1  16.7000           0   \n",
       "873       3           0         1  47.0      0      0   9.0000           0   \n",
       "182       3           0         1   9.0      4      2  31.3875           0   \n",
       "876       3           0         1  20.0      0      0   9.8458           0   \n",
       "\n",
       "     Embarked_Q  Embarked_S  \n",
       "30            0           0  \n",
       "10            0           1  \n",
       "873           0           1  \n",
       "182           0           1  \n",
       "876           0           1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the training set\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "xWaziU030-5T"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex_female  Sex_male   Age  SibSp  Parch     Fare  Embarked_C  \\\n",
       "707       1           0         1  42.0      0      0  26.2875           0   \n",
       "37        3           0         1  21.0      0      0   8.0500           0   \n",
       "615       2           1         0  24.0      1      2  65.0000           0   \n",
       "169       3           0         1  28.0      0      0  56.4958           0   \n",
       "68        3           1         0  17.0      4      2   7.9250           0   \n",
       "\n",
       "     Embarked_Q  Embarked_S  \n",
       "707           0           1  \n",
       "37            0           1  \n",
       "615           0           1  \n",
       "169           0           1  \n",
       "68            0           1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the validation set\n",
    "X_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yT0wl3Pi8kLY"
   },
   "source": [
    "**Understanding feature's relation by data visualization:**\\\n",
    "We can continue to analyze attributes using visualizations. Histograms can help us visualize the relationship between different features, such as age and gender in the figures below. In the 2 figures below, we see a slightly different distribution between men and women, related to age. In men, this distribution is relatively uniform (except for a peak around age 30), but for women, there is a greater proportion between age 18 and 30. The visualization helps to quickly get an idea of the attribute distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "BHFpYYhz8krN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fb784402be0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Y = pd.read_csv(\"train.csv\")\n",
    "data_vis= sns.FacetGrid(X_train, col='Sex_female')\n",
    "data_vis.map(plt.hist, 'Age', bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7A6AWX7-lSb"
   },
   "source": [
    "**(TO DO) Q2 - 2 marks** \\\n",
    "(part a) Use data visualisation (as above) to show the relation between:\n",
    "\n",
    "1.   Gender and fare paid.\n",
    "2.   Gender and port of embarcation (either C, Q or S).\n",
    "\n",
    "Present (part b) your interpretation of the histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "WpZUrRwIDvEL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fb784347d90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ANSWER Q2 (part a):\n",
    "data_vis= sns.FacetGrid(X_train, col='Sex_female')\n",
    "data_vis2=sns.FacetGrid(X_train, col='Sex_female')\n",
    "data_vis.map(plt.hist,'Fare', bins=50)\n",
    "data_vis2.map(plt.hist,'Embarked_Q',bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CHKOlKoEBDf"
   },
   "source": [
    "**ANSWER Q2 - part b** \\\n",
    "According to the histogram above they have created a similar pattern in temrs of fare for both genders. There seems to be more men distributed for the different prices of the Fare however compared to women this could mean that there may have been more men on aboard than female. There seems to be the same number of men and women who embarkked on port Q both have very few people embarking on this port.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuUu0w510-5T"
   },
   "source": [
    "**4. Evaluation techniques**    \n",
    "\n",
    "Now that we have our training and validation set, we are almost ready to learn models with various learning algorithms. But once these models are learned, we will want to evaluate them. So let's first define our evaluation metrics.\n",
    "\n",
    "Later on we will be using more evaluation techniques to better evaluate the performance of the models. For now, we will define functions to calculate the *Precision*, *Recall*, and *Accuracy* metrics. \n",
    "\n",
    "Precision and recall were discussed in the previous notebook.  The *Accuracy* represents what percentage of classifications the model correctly made. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "FtcTqHkY0-5T"
   },
   "outputs": [],
   "source": [
    "def precision(actualTags, predictions, classOfInterest):\n",
    "    '''\n",
    "    Calculates the precision for a specific class, given the ground truth and predicted values.\n",
    "    '''\n",
    "    totalFound = 0\n",
    "    for i in range(len(actualTags)):\n",
    "        if (actualTags[i] == classOfInterest and actualTags[i] == predictions[i]):\n",
    "            totalFound += 1\n",
    "    return totalFound / np.count_nonzero(predictions == classOfInterest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "y-PonRBj0-5T"
   },
   "outputs": [],
   "source": [
    "def recall(actualTags, predictions, classOfInterest):\n",
    "    '''\n",
    "    Calculates the recall for a specific class, given the ground truth and predicted values.\n",
    "    '''\n",
    "    totalFound = 0\n",
    "    for i in range(len(actualTags)):\n",
    "        if (actualTags[i] == classOfInterest and actualTags[i] == predictions[i]):\n",
    "            totalFound += 1\n",
    "    return totalFound / np.count_nonzero(actualTags == classOfInterest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Jm4ECsc20-5T"
   },
   "outputs": [],
   "source": [
    "def accuracy(actualTags, predictions):\n",
    "    '''\n",
    "    Calculates the average number of correct predictions.\n",
    "        - actualTags: The ground truth\n",
    "        - predictions: What the model predicts\n",
    "    '''\n",
    "    totalFound = 0\n",
    "    for i in range(len(actualTags)):\n",
    "        if (actualTags[i] == predictions[i]):\n",
    "            totalFound += 1\n",
    "    return totalFound / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "2bNEP3NT0-5T"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of calculating accuracy\n",
    "accuracy([0, 1, 1, 1, 0], [1, 1, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uyrn5Grr0-5T"
   },
   "source": [
    "**5. Naive Bayes**    \n",
    "\n",
    "With the data preprocessed and several evaluation functions defined, we are now ready to use some Machine Learning algorithms to perform the predictions of whether or not a passenger survived on the Titanic.    \n",
    "\n",
    "The first approach that we will use is the Naive Bayes algorithm provided by scikit-learn. This will be a very similar process to what you have done in notebook 4. You will train the model by calling the *fit* function and will retrieve predictions from the model by calling the *predict* function. Unlike last notebook, we already have all of our data preprocessed as numerical features within a pandas dataframe, with the class labels as numpy arrays (y_train and y_val). Thus we will not need to perform any transformations, such as those that were performed in notebook 4.  \n",
    "\n",
    "The first task is to train the model with the .fit() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "GqxmjGBf0-5T"
   },
   "outputs": [],
   "source": [
    "# Train the model with the training set by calling the .fit() function\n",
    "# X_train contains the features used to train the model\n",
    "# y_train contains the class labels for the samples from X_train\n",
    "clf_nb = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZKPvEXN0-5U"
   },
   "source": [
    "We can get then view how the algorithm performs when predicting the samples in the training set through the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "FqvTWl550-5U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing the first ten actual values to the predicted values:\n",
      "[0 1 0 0 0 0 0 1 1 0]\n",
      "[0 1 0 1 0 0 0 0 0 0]\n",
      "Calculating the total accuracy for the training set:\n",
      "0.6980337078651685\n"
     ]
    }
   ],
   "source": [
    "print(\"Comparing the first ten actual values to the predicted values:\")\n",
    "# Print the first ten class labels for the training set\n",
    "print(y_train[0:10])\n",
    "# Predict whether the passengers did or did not survive the Titanic on the training set\n",
    "nb_train_predictions = clf_nb.predict(X_train)\n",
    "# Print the first ten predictions\n",
    "print(nb_train_predictions[0:10])\n",
    "print(\"Calculating the total accuracy for the training set:\")\n",
    "print(accuracy(y_train, nb_train_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3kGj7OB0-5U"
   },
   "source": [
    "From the above, we can see that after being trained, the model can correctly predict just under 70% of all samples from the training set. But how well does it perform on the validation set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vuCcSuJn0-5U"
   },
   "source": [
    "**(TO DO) Q3 - 3 marks**   \n",
    "Following the example provided above, obtain the predictions from the Naive Bayes model on the entire validation set (X_val, y_val) and print the precision, recall, and accuracy for the validation set (for precision and recall, print individually for both classes, 1 and 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "nQevFw0jHOb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision when class = 0: 0.6535433070866141\n",
      "Precision when class = 1: 0.6730769230769231\n",
      "Recall when class = 0: 0.83\n",
      "Recall when class = 1: 0.4430379746835443\n",
      "Accuracy: 0.659217877094972\n"
     ]
    }
   ],
   "source": [
    "# ANSWER Q3 \n",
    "\n",
    "# Get the predictions for the validation set\n",
    "nb_val_predictions = clf_nb.predict(X_val)\n",
    "# Retrieve and print the precision values for class 1 and class 0\n",
    "print(\"Precision when class = 0: \" + str(precision(y_val,nb_val_predictions,0)))\n",
    "print(\"Precision when class = 1: \" + str(precision(y_val,nb_val_predictions,1)))\n",
    "# Retrieve and print the recall values for class 1 and class 0\n",
    "print(\"Recall when class = 0: \" + str(recall(y_val,nb_val_predictions,0)))\n",
    "print(\"Recall when class = 1: \" + str(recall(y_val,nb_val_predictions,1)))\n",
    "# Retrieve and print the accuracy for the model\n",
    "print(\"Accuracy: \" + str(accuracy(y_val, nb_val_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTiP4vCh0-5U"
   },
   "source": [
    "**6. Logistic Regression**    \n",
    "\n",
    "We will now try using another Machine Learning algorithm that may or may not perform better than the Naive Bayes approach. Specifically, we will use the Logistic Regression Machine Learning algorithm to predict who did and did not survive on the Titanic.    \n",
    "\n",
    "Since the Logistic Regression algorithm that we will be using also comes from scikit-learn, the general process will be nearly identical to what we have done for the Naive Bayes classifier. The main difference is that we will now be using a different algorithm that contains some options that we will need to set. All of the details of possible ways to tune the Logistic Regression model are available [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).     \n",
    "\n",
    "We will first initialize and train the model with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "WEyQJU5o0-5U"
   },
   "outputs": [],
   "source": [
    "# Train the model with the training set by calling the .fit() function\n",
    "# X_train contains the features used to train the model\n",
    "# y_train contains the class labels for the samples from X_train\n",
    "clf_lr = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mOIweR1R0-5U"
   },
   "source": [
    "Next, we will view how the model performs on the training data to get an idea as to how the training went. Since we trained on this data, we will hopefully have strong results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "rEhPonk80-5U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing the first ten actual values to the predicted values:\n",
      "[0 1 0 0 0 0 0 1 1 0]\n",
      "[0 1 0 0 0 0 0 1 0 0]\n",
      "Calculating the total accuracy for the training set:\n",
      "0.8103932584269663\n"
     ]
    }
   ],
   "source": [
    "print(\"Comparing the first ten actual values to the predicted values:\")\n",
    "# Print the first ten class labels for the training set\n",
    "print(y_train[0:10])\n",
    "# Predict whether the passengers did or did not survive the Titanic on the training set\n",
    "lr_train_predictions = clf_lr.predict(X_train)\n",
    "# Print the first ten predictions\n",
    "print(lr_train_predictions[0:10])\n",
    "print(\"Calculating the total accuracy for the training set:\")\n",
    "print(accuracy(y_train, lr_train_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yghkCkt0-5U"
   },
   "source": [
    "**(TO DO) Q4 - 3 marks**   \n",
    "Following the example provided above, obtain the predictions from the Logistic Regression model on the validation set (X_val, y_val) and print the precision, recall, and accuracy for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "MMsxlL7gHdYS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision when class = 0: 0.7583333333333333\n",
      "Precision when class = 1: 0.847457627118644\n",
      "Recall when class = 0: 0.91\n",
      "Recall when class = 1: 0.6329113924050633\n",
      "Accuracy: 0.7877094972067039\n"
     ]
    }
   ],
   "source": [
    "# ANSWER Q4 - \n",
    "\n",
    "# Get the predictions for the validation set\n",
    "lr_val_predictions = clf_lr.predict(X_val)\n",
    "# Retrieve and print the precision values for class 1 and class 0\n",
    "print(\"Precision when class = 0: \" + str(precision(y_val,lr_val_predictions,0)))\n",
    "print(\"Precision when class = 1: \" + str(precision(y_val,lr_val_predictions,1)))\n",
    "# Retrieve and print the recall values for class 1 and class 0\n",
    "print(\"Recall when class = 0: \" + str(recall(y_val,lr_val_predictions,0)))\n",
    "print(\"Recall when class = 1: \" + str(recall(y_val,lr_val_predictions,1)))\n",
    "# Retrieve and print the accuracy for the model\n",
    "print(\"Accuracy: \" + str(accuracy(y_val, lr_val_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eb6WiAEf0-5V"
   },
   "source": [
    "**7. More evaluation techniques**    \n",
    "\n",
    "Now that you have trained and tested the models above, you will define two additional evaluation methods. The first will be the Micro-average on precisions and the second will be the Macro-average on precisions. Definitions for these can be found in your course material from Module 4 on Supervised Machine Learning (part 4 - Evaluation).   \n",
    "\n",
    "Although we can also define the Micro- and Macro-averages on recalls, we will not do that for this notebook to avoid having too many evaluation metrics to consider. In reality, each dataset will have evaluation criteria that are more and less important depending on the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kB3cXYX0-5V"
   },
   "source": [
    "**(TO DO) Q5 - 2 marks**   \n",
    "In the cell below, complete the definition of the micro_precision_average function. You must use only the parameters provided and cannot use any functionality from scikit-learn's library.  It would be easier to use the function from sklearn, but the purpose here is to learn how to write it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "kaxzsQTEHtwi"
   },
   "outputs": [],
   "source": [
    "# ANSWER Q5 - \n",
    "def micro_precision_average(actualTags, predictions, class1, class2):\n",
    "    '''\n",
    "    Calculates the Micro-average on precisions.\n",
    "        - actualTags: The ground truth\n",
    "        - predictions: The predicted class values\n",
    "        - class1: The value of the first class\n",
    "        - class2: The value of the second class\n",
    "    '''\n",
    "    truePositivec1=0\n",
    "    truePositivec2=0\n",
    "    falsePositivec1=0\n",
    "    falsePositivec2=0\n",
    "    for tag, pred in zip(actualTags, predictions):\n",
    "        if pred==class1:\n",
    "            if tag==pred:\n",
    "                truePositivec1+=1\n",
    "            else:\n",
    "                falsePositivec1+=1\n",
    "        else:\n",
    "            if tag==pred:\n",
    "                truePositivec2+=1\n",
    "            else:\n",
    "                falsePositivec2+=1\n",
    "    return (truePositivec1+truePositivec2)/(truePositivec1+falsePositivec1+truePositivec2+falsePositivec2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ju01dU580-5V"
   },
   "source": [
    "**(TO DO) Q6 - 2 marks**   \n",
    "In the cell below, complete the definition of the macro_precision_average function. You must use only the parameters provided and cannot use any functionality from scikit-learn's library, since again, the goal is to learn how to write the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "_oJUDy1jH7Cr"
   },
   "outputs": [],
   "source": [
    "# ANSWER Q6 - \n",
    "def macro_precision_average(actualTags, predictions, class1, class2):\n",
    "    '''\n",
    "    Calculates the Macro-average on precisions.\n",
    "        - actualTags: The ground truth\n",
    "        - predictions: The predicted class values\n",
    "        - class1: The value of the first class\n",
    "        - class2: The value of the second class\n",
    "    '''\n",
    "    class1precision=precision(actualTags,predictions,class1)\n",
    "    class2precision=precision(actualTags,predictions,class2)\n",
    "    return (class1precision+class2precision)/2\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNaTFl8D0-5V"
   },
   "source": [
    "**(TO DO) Q7 - 2 marks**   \n",
    "To test these evaluation functions, evaluate the Micro- and Macro-averages on the precisions from your testing on the validation set with both the Naive Bayes and Logistic Regression models. Print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "xlndYT_ElLRT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Naive Bayes:\n",
      "The Micro Precision Average is: 0.659217877094972\n",
      "The Macro Precision Average is: 0.6633101150817686\n",
      "For Logistic Regression:\n",
      "The Micro Precision Average is: 0.7877094972067039\n",
      "The Macro Precision Average is: 0.8028954802259887\n"
     ]
    }
   ],
   "source": [
    "# ANSWER Q7 - \n",
    "\n",
    "print(\"For Naive Bayes:\")\n",
    "print(\"The Micro Precision Average is: \"+str(micro_precision_average(y_val,nb_val_predictions,0,1)))\n",
    "print(\"The Macro Precision Average is: \"+str(macro_precision_average(y_val,nb_val_predictions,0,1)))\n",
    "print(\"For Logistic Regression:\")\n",
    "print(\"The Micro Precision Average is: \"+str(micro_precision_average(y_val,lr_val_predictions,0,1)))\n",
    "print(\"The Macro Precision Average is: \"+str(macro_precision_average(y_val,lr_val_predictions,0,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANPkAxkA0-5V"
   },
   "source": [
    "**8. Discussion**    \n",
    "\n",
    "As with all Machine Learning experiments, we must use the results obtained to understand which model is better and why. In this scenario we have the precision, recall, average, micro-average, and macro-average values. Below is a discussion question separated into sections for you to answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMUu5vd90-5V"
   },
   "source": [
    "**(TO DO) Q8 (a) - 2 marks**   \n",
    "Copy the outputs for the precision, recall, accuracy, micro-average, and macro-average obtained for both models below (only from the validation tests). Enter each value in the corresponding <td\\> </td\\> tag. For each evaluation approach, mention which Machine Learning model provides the better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YypqY0sIKieR"
   },
   "source": [
    "**ANSWER Q8(a) -** \\\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td><strong>Naive Bayes</strong></td>\n",
    "        <td><strong>Logistic Regression</strong></td>\n",
    "        <td><strong>Better Model</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Precision (class=0)</strong></td>\n",
    "        <td>0.6535433070866141</td>\n",
    "        <td>0.7583333333333333</td>\n",
    "        <td><strong>Logistic Regression</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Precision (class=1)</strong></td>\n",
    "        <td>0.6730769230769231</td>\n",
    "        <td>0.847457627118644</td>\n",
    "        <td><strong>Logistic Regression</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Recall (class=0)</strong></td>\n",
    "        <td>0.83</td>\n",
    "        <td>0.91</td>\n",
    "        <td><strong>Logistic Regression</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Recall (class=1)</strong></td>\n",
    "        <td>0.4430379746835443</td>\n",
    "        <td>0.6329113924050633</td>\n",
    "        <td><strong>Logistic Regression</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Accuracy</strong></td>\n",
    "        <td>0.659217877094972</td>\n",
    "        <td>0.7877094972067039</td>\n",
    "        <td><strong>Logistic Regression</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Micro Average Precision</strong></td>\n",
    "        <td>0.659217877094972</td>\n",
    "        <td>0.7877094972067039</td>\n",
    "        <td><strong>Logistic Regression</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Macro Average Precision</strong></td>\n",
    "        <td>0.6633101150817686</td>\n",
    "        <td>0.8028954802259887</td>\n",
    "        <td><strong>Logistic Regression</strong></td>\n",
    "    </tr>    \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfnzv6h40-5V"
   },
   "source": [
    "**(TO DO) Q8 (b) - 2 marks**   \n",
    "Based on your results, which model performs better at predicting whether a passenger does or does not survive on the Titanic? Justify your answer.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQy2TVOtLbVb"
   },
   "source": [
    "**ANSWER Q8 (b) -** \\\n",
    "The Logisitc regression model seems to perform better at justifying which passengers surived or did not survive since in all the categories for the evaluations the Logisitic regression model has beaten th Naive Bayes Classifier model. This can be due to the minimization of errors the Logistic regression model does as it trains through the 1000 iterations to change the weighting of features in the gradient descent process to allow the model to have more accurate predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce3am_ab0-5W"
   },
   "source": [
    "**9. Balancing the class distribution**    \n",
    "\n",
    "As mentioned at the beginning of the notebook, this dataset contains more passengers that did not survived on the Titanic than those who did survive. This results in a class imbalance where the majority class (0) contains more instances than the minority class (1). There are many methods of handling this problem. One method is to simply take the minority class and, through some method, produce more instances of that class. For example, a trivial method could be to randomly select a number instances and duplicate them to match the number of instances from the majority class. This concept is called *oversampling*. You can also remove instances from the majority class to balance the class distribution (called *undersampling*).    \n",
    "\n",
    "For this notebook, oversampling will be performed via imblearn's implementation of a technique called SMOTE. Understanding SMOTE is beyond the scope of this notebook, but more information can be found [here](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/). The important thing to understand is that the number of instances for each class value will be the same by artificially creating new instances of passengers who survived from the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "mUagI1fD0-5W"
   },
   "outputs": [],
   "source": [
    "# Define the SMOTE instance\n",
    "smote = SMOTE(random_state=0, sampling_strategy=\"minority\")\n",
    "# Retrieve the oevrsampled data\n",
    "X_os, y_os = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qa4wJ3E0-5W"
   },
   "source": [
    "Note that the oversampled dataset is now defined within X_os and y_os, not X and y. We will be using these values for the remainder of the notebook. Below we now look at how many instances in our new dataset contain the class 0 and how many contain the class 1. These values are now balanced when compared to the plot shown in section 1 of this notebook. Note that X_os is now a numpy array rather than a dataframe due to this conversion. This changes nothing regarding how we use it, but changes the method of plotting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "u8I-LOmy0-5W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 contains 549 instances.\n",
      "1 contains 549 instances.\n"
     ]
    }
   ],
   "source": [
    "# Print the number of instances for each class\n",
    "class_names, totals = np.unique(y_os, return_counts=True)\n",
    "print(str(class_names[0]) + \" contains \" + str(totals[0]) + \" instances.\")\n",
    "print(str(class_names[1]) + \" contains \" + str(totals[1]) + \" instances.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ndp2TvvF0-5W"
   },
   "source": [
    "With the oversampled dataset, we will now define our new train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "ClkAjTSo0-5W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878, 10)\n",
      "(220,)\n"
     ]
    }
   ],
   "source": [
    "# split the large dataset into train and test\n",
    "X_train_os, X_val_os, y_train_os, y_val_os = train_test_split(X_os, y_os, test_size = 0.2, random_state=2)\n",
    "# Look at the shape of the outputs\n",
    "print(X_train_os.shape)\n",
    "print(y_val_os.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8BgGhAN0-5W"
   },
   "source": [
    "With this all defined, we will now train and test a new Naive Bayes and Logistic Regression model, evaluate the models, and determine whether the oversampling provided better results than without the oversampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0oD1K_V0-5W"
   },
   "source": [
    "**(TO DO) Q9 - 10 marks total**   \n",
    "Repeat the Machine Learning experiment performed throughout the previous sections on the new oversampled data. Ensure that you use the appropriate names (***do not forget the _os in the names*** to avoid incorrect solutions).     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQ4WQOo10-5W"
   },
   "source": [
    "**(TO DO) Q9 (a) - 3 marks**   \n",
    "Train, test, and evaluate the validation set (with all evaluation metrics) with a Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "4wGKDEz0MQw6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision when class = 0: 0.5874125874125874\n",
      "Precision when class = 1: 0.7662337662337663\n",
      "Recall when class = 0: 0.8235294117647058\n",
      "Recall when class = 1: 0.5\n",
      "Accuracy: 0.65\n",
      "The Micro Precision Average is: 0.65\n",
      "The Macro Precision Average is: 0.6768231768231768\n"
     ]
    }
   ],
   "source": [
    "# ANSWER Q9(a) --\n",
    "clf_nb = MultinomialNB().fit(X_train_os, y_train_os)\n",
    "nb_val_predictionsOS = clf_nb.predict(X_val_os)\n",
    "print(\"Precision when class = 0: \" + str(precision(y_val_os,nb_val_predictionsOS,0)))\n",
    "print(\"Precision when class = 1: \" + str(precision(y_val_os,nb_val_predictionsOS,1)))\n",
    "print(\"Recall when class = 0: \" + str(recall(y_val_os,nb_val_predictionsOS,0)))\n",
    "print(\"Recall when class = 1: \" + str(recall(y_val_os,nb_val_predictionsOS,1)))\n",
    "print(\"Accuracy: \" + str(accuracy(y_val_os, nb_val_predictionsOS)))\n",
    "print(\"The Micro Precision Average is: \"+str(micro_precision_average(y_val_os,nb_val_predictionsOS,0,1)))\n",
    "print(\"The Macro Precision Average is: \"+str(macro_precision_average(y_val_os,nb_val_predictionsOS,0,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PE_4uedU0-5W"
   },
   "source": [
    "**(TO DO) Q9 (b) - 3 marks**   \n",
    "Train, test, and evaluate the validation set (with all evaluation metrics) with a Logistic Regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "9nqKE5dxMXxJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision when class = 0: 0.8035714285714286\n",
      "Precision when class = 1: 0.8888888888888888\n",
      "Recall when class = 0: 0.8823529411764706\n",
      "Recall when class = 1: 0.8135593220338984\n",
      "Accuracy: 0.8454545454545455\n",
      "The Micro Precision Average is: 0.8454545454545455\n",
      "The Macro Precision Average is: 0.8462301587301587\n"
     ]
    }
   ],
   "source": [
    "# ANSWER Q9(b) --\n",
    "clf_lr = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1).fit(X_train_os, y_train_os)\n",
    "lr_val_predictionsOS = clf_lr.predict(X_val_os)\n",
    "print(\"Precision when class = 0: \" + str(precision(y_val_os,lr_val_predictionsOS,0)))\n",
    "print(\"Precision when class = 1: \" + str(precision(y_val_os,lr_val_predictionsOS,1)))\n",
    "print(\"Recall when class = 0: \" + str(recall(y_val_os,lr_val_predictionsOS,0)))\n",
    "print(\"Recall when class = 1: \" + str(recall(y_val_os,lr_val_predictionsOS,1)))\n",
    "print(\"Accuracy: \" + str(accuracy(y_val_os, lr_val_predictionsOS)))\n",
    "print(\"The Micro Precision Average is: \"+str(micro_precision_average(y_val_os, lr_val_predictionsOS,0,1)))\n",
    "print(\"The Macro Precision Average is: \"+str(macro_precision_average(y_val_os, lr_val_predictionsOS,0,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzB4H9Vf0-5X"
   },
   "source": [
    "**(TO DO) Q9 (c) - 2 marks**   \n",
    "Compare the results between the above two experiments (from Q9 (a) and Q9 (b)), which model is better and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9sRlrgyMdbx"
   },
   "source": [
    "**ANSWER Q9(c) -** \\\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td><strong>Naive Bayes (oversampled)</strong></td>\n",
    "        <td><strong>Logistic Regression (oversampled)</strong></td>\n",
    "        <td><strong>Better Model</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Precision (class=0)</strong></td>\n",
    "        <td>0.587412587412587</td>\n",
    "        <td>0.8035714285714286</td>\n",
    "        <td><strong>Logistic Regression (oversampled)</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Precision (class=1)</strong></td>\n",
    "        <td>0.7662337662337663</td>\n",
    "        <td>0.8888888888888888</td>\n",
    "        <td><strong>Logistic Regression (oversampled)</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Recall (class=0)</strong></td>\n",
    "        <td>0.8235294117647058</td>\n",
    "        <td>0.8823529411764706</td>\n",
    "        <td><strong>Logistic Regression (oversampled)</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Recall (class=1)</strong></td>\n",
    "        <td>0.5</td>\n",
    "        <td>0.8135593220338984</td>\n",
    "        <td><strong>Logistic Regression (oversampled)</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Accuracy</strong></td>\n",
    "        <td>0.65</td>\n",
    "        <td>0.8454545454545455</td>\n",
    "        <td><strong>Logistic Regression (oversampled)</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Micro Average Precision</strong></td>\n",
    "        <td>0.65</td>\n",
    "        <td>0.8454545454545455</td>\n",
    "        <td><strong>Logistic Regression (oversampled)</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><strong>Macro Average Precision</strong></td>\n",
    "        <td>0.6768231768231768</td>\n",
    "        <td>0.8462301587301587</td>\n",
    "        <td><strong>Logistic Regression (oversampled)</strong></td>\n",
    "    </tr>    \n",
    "</table>        \n",
    "\n",
    "The Logistic regression model was better than the naive bayes model since it had a better evauation score in each catagory compared to the naive bayes scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FczVX4Qk0-5X"
   },
   "source": [
    "**(TO DO) Q9 (d) - 2 marks**   \n",
    "Does the model selected from Q9 (c) perform better or worse than the model selected in Q8 (b)? Does this mean that the oversampling helps the Machine Learning learn better or worse in this scenario? Justify your answer.    \n",
    "\n",
    "Note: There is no need to put all the data in another table (you certainly can if you would like to better organize it). Just provide the answers along with justifications as to why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbSlSJ7-Mk2p"
   },
   "source": [
    "**ANSWER Q9(d) -** \\\n",
    "The better model selected from Q9(c) and Q8(b) was the Logistic Regression model and this model has performed even better after the oversampling process in almost all categories after the oversampling data. Some categories did drop but that can be a consequence from the oversampling data. \\\n",
    "The oversampling has helped the model better other scenarios since ther wasan increase in the datapoints for the training set. The extra data may not be unique but it gives better training to help minimize the error for the prediction in each iteration. Overall the weights are now more balanced for surviving and non-surving passengers and can make better predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icZSWXLs0-5X"
   },
   "source": [
    "***SIGNATURE:***\n",
    "My name is Sy Rajeswaran\n",
    "My student number is 300005333\n",
    "I certify being the author of this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CSI4106_SMLTitanic_Fall2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
